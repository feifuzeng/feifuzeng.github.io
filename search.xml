<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[自定义注解-方法重试@RetryProcess]]></title>
    <url>%2F2019%2F06%2F20%2F%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3-%E6%96%B9%E6%B3%95%E9%87%8D%E8%AF%95%2F</url>
    <content type="text"><![CDATA[背景在项目开发中，有时候会出现接口调用失败，本身调用又是异步的，如果是因为一些网络问题请求超时，总想可以重试几次把任务处理掉。 一些RPC框架，比如dubbo都是有重试机制的，但是并不是每一个项目多会使用dubbo框架，常规的小项目有时候直接使用http进行不同项目之间的交互。 思路使用spring aop和自定义注解来，建立一套重试机制。根据切入点和自定义注解，来完成重试工作。 自定义注解定义注解12345678910111213141516171819202122232425package com.github.feifuzeng.study.annotation;import org.springframework.stereotype.Component;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * @author feifz * @version 1.0.0 * @Description 重试机制自定义注解 * @createTime 2019年06月20日 14:05:00 */@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface RetryProcess &#123; int value() default 1; int sleep() default 1000;&#125; 注解中value参数为重试次数，默认为1，sleep为重试间隔，默认为1000毫秒。 定义切面12345678910111213141516171819202122232425262728293031323334353637383940414243package com.github.feifuzeng.study.annotation;/** * @author feifz * @version 1.0.0 * @Description 重试注解切面 * @createTime 2019年06月20日 14:07:00 */import lombok.extern.log4j.Log4j2;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint;import org.springframework.stereotype.Component;import java.util.concurrent.atomic.AtomicInteger;@Aspect@Component@Log4j2public class RetryProcessAspect &#123; private AtomicInteger atomicInteger = new AtomicInteger(0); @AfterThrowing(pointcut=("@annotation(com.github.feifuzeng.study.annotation.RetryProcess)")) public void tryAgain(JoinPoint point) &#123; try &#123; MethodSignature methodSignature = (MethodSignature) point.getSignature(); RetryProcess retryProcess = methodSignature.getMethod().getAnnotation(RetryProcess.class); if (atomicInteger.intValue() &lt; retryProcess.value()) &#123; int i = atomicInteger.incrementAndGet(); Thread.sleep(retryProcess.sleep() * i); log.debug("开始重试第" + i + "次"); MethodInvocationProceedingJoinPoint methodPoint = ((MethodInvocationProceedingJoinPoint) point); methodPoint.proceed(); &#125; &#125; catch (Throwable throwable) &#123; tryAgain(point); &#125; &#125;&#125; 使用示例1234@RetryProcess(value = 2,sleep = 2000) public List&lt;User&gt; findList() &#123; return userMapper.queryUserList(); &#125; 该自定义注解用于方法上，当改方法在执行过程中存在异常，不管是系统异常还是手动抛出的业务异常，均可实现重试。 参考 https://www.cnblogs.com/tom-plus/p/7844228.html]]></content>
      <categories>
        <category>注解</category>
      </categories>
      <tags>
        <tag>自定义注解</tag>
        <tag>方法重试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前后端API交互如何保证数据安全性？]]></title>
    <url>%2F2019%2F06%2F17%2F%E5%89%8D%E5%90%8E%E7%AB%AFAPI%E4%BA%A4%E4%BA%92%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E6%80%A7%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[前言前后端分离的开发方式，我们以接口为标准来进行推动，定义好接口，各自开发自己的功能，最后进行联调整合。无论是开发原生的APP还是webapp还是PC端的软件,只要是前后端分离的模式，就避免不了调用后端提供的接口来进行业务交互。网页或者app，只要抓下包就可以清楚的知道这个请求获取到的数据，这样的接口对爬虫工程师来说是一种福音，要抓你的数据简直轻而易举。数据的安全性非常重要，特别是用户相关的信息，稍有不慎就会被不法分子盗用，所以我们对这块要非常重视，容不得马虎。 如何保证API调用时数据的安全性？ 通信使用https 请求签名，防止参数被篡改 身份确认机制，每次请求都要验证是否合法 APP中使用ssl pinning防止抓包操作 对所有请求和响应都进行加解密操作 等等方案……. 对所有请求和响应都进行加解密操作方案有很多种，当你做的越多，也就意味着安全性更高，今天我跟大家来介绍一下对所有请求和响应都进行加解密操作的方案，即使能抓包，即使能调用我的接口，但是我返回的数据是加密的，只要加密算法够安全，你得到了我的加密内容也对我没什么影响。像这种工作最好做成统一处理的，你不能让每个开发都去关注这件事情，如果让每个开发去关注这件事情就很麻烦了，返回数据时还得手动调用下加密的方法，接收数据后还得调用下解密的方法。为此，我基于Spring Boot封装了一个Starter, 内置了AES加密算法。GitHub地址如下：https://github.com/feifuzeng/spring-boot-starter-encrypt 入门使用 下载源码并在项目工程中引入 在启动类上增加加解密注解在启动类上增加@EnableEncrypt注解开启加解密操作： 1234567@EnableEncrypt@SpringBootApplicationpublic class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class, args); &#125;&#125; 配置文件增加配置 12spring.encrypt.key=abcdef0123456789spring.encrypt.debug=false spring.encrypt.key：加密key，必须是16位spring.encrypt.debug：是否开启调试模式,默认为false,如果为true则不启用 加解密操作为了考虑通用性，不会对所有请求都执行加解密，基于注解来做控制响应数据需要加密的话，就在Controller的方法上加@Encrypt注解即可。123456789101112@Encrypt@RequestMapping("/list")@ResponseBodypublic List&lt;User&gt; query()&#123; List&lt;User&gt; list = new ArrayList&lt;&gt;(); User user = new User(); user.setGender(1); user.setId("1"); user.setName("11111"); list.add(user); return list;&#125; 当我们访问/list接口时，返回的数据就是加密之后base64编码的格式。还有一种操作就是前端提交的数据，分为2种情况，一种是get请求，这种暂时没处理，后面再考虑，目前只处理的post请求，基于json格式提交的方式，也就是说后台需要用@RequestBody接收数据才行, 需要解密的操作我们加上@Decrypt注解即可。123456789@Encrypt@Decrypt@RequestMapping("/queryList")@ResponseBodypublic List&lt;User&gt; queryList(@RequestBody User user)&#123; List&lt;User&gt; list = new ArrayList&lt;&gt;(); list.add(user); return list;&#125; 加了@Decrypt注解后，前端提交的数据需要按照AES加密算法，进行加密，然后提交到后端，后端这边会自动解密，然后再映射到参数对象中。上面讲解的都是后端的代码，前端使用的话我们以js来讲解，当然你也能用别的语言来做。前端需要做的就2件事情： 统一处理数据的响应，在渲染到页面之前进行解密操作 当有POST请求的数据发出时，统一加密js加密文件请参考我GitHub中示例工程中引入的js文件示例代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;数据传输解密示例&lt;/title&gt; &lt;/head&gt; &lt;script type="text/javascript" src = "js/aes.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src = "js/crypto-js.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src = "js/pad-zeropadding.js"&gt;&lt;/script&gt; &lt;script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"&gt;&lt;/script&gt;&lt;body&gt; &lt;input type="button" value="获取数据" onclick="getData()"/&gt; &lt;hr&gt; &lt;br&gt; 姓名：&lt;input type="text" id="name" /&gt;&lt;br&gt; 性别：&lt;input type="text" id="gender" /&gt;&lt;br&gt; &lt;input type="button" value="发送数据" onclick="sendData()"/&gt; &lt;script&gt; var backUrl =''; //var backUrl ='http://localhost:8080'; function getData() &#123; $.ajax(&#123; type: "GET", url:backUrl+"/user/list", success: function(resData) &#123; alert("返回的数据："+resData); alert("解密之后的数据："+Decrypt(resData)); &#125; &#125;); &#125; function sendData() &#123; var name=document.getElementById("name").value; var gender=document.getElementById("gender").value; alert("发送的数据："+JSON.stringify(&#123;"name":name,"gender":gender&#125;)); $.ajax(&#123; type: "POST", url:backUrl+"/user/queryList", data:JSON.stringify(&#123;"name":name,"gender":gender&#125;), dataType:'json', contentType: "application/json", success: function(resData) &#123; alert("返回的数据："+resData); alert("解密之后："+Decrypt(resData)); &#125; &#125;); &#125; var key = CryptoJS.enc.Utf8.parse("abcdef0123456789"); function Encrypt(word) &#123; var srcs = CryptoJS.enc.Utf8.parse(word); var encrypted = CryptoJS.AES.encrypt(srcs, key, &#123; mode : CryptoJS.mode.ECB, padding : CryptoJS.pad.Pkcs7 &#125;); return encrypted.toString(); &#125; function Decrypt(word) &#123; var decrypt = CryptoJS.AES.decrypt(word, key, &#123; mode : CryptoJS.mode.ECB, padding : CryptoJS.pad.Pkcs7 &#125;); return CryptoJS.enc.Utf8.stringify(decrypt).toString(); &#125; &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 到此为止，我们就为整个前后端交互的通信做了一个加密的操作，只要加密的key不泄露，别人得到你的数据也没用，问题是如何保证key不泄露呢？服务端的安全性较高，可以存储在数据库中或者配置文件中，毕竟在我们自己的服务器上，最危险的其实就时前端了，app还好，可以打包，但是要防止反编译等等问题。如果是webapp则可以依赖于js加密来实现，下面我给大家介绍一种动态获取加密key的方式，只不过实现起来比较复杂，我们不上代码，只讲思路：加密算法有对称加密和非对称加密，AES是对称加密，RSA是非对称加密。之所以用AES加密数据是因为效率高，RSA运行速度慢,可以用于签名操作。我们可以用这2种算法互补，来保证安全性，用RSA来加密传输AES的秘钥，用AES来加密数据，两者相互结合，优势互补。其实大家理解了HTTPS的原理的话对于下面的内容应该是一看就懂的，HTTPS比HTTP慢的原因都是因为需要让客户端与服务器端安全地协商出一个对称加密算法。剩下的就是通信时双方使用这个对称加密算法进行加密解密。客户端启动，发送请求到服务端，服务端用RSA算法生成一对公钥和私钥，我们简称为pubkey1,prikey1，将公钥pubkey1返回给客户端。客户端拿到服务端返回的公钥pubkey1后，自己用RSA算法生成一对公钥和私钥，我们简称为pubkey2,prikey2，并将公钥pubkey2通过公钥pubkey1加密，加密之后传输给服务端。此时服务端收到客户端传输的密文，用私钥prikey1进行解密，因为数据是用公钥pubkey1加密的，通过解密就可以得到客户端生成的公钥pubkey2然后自己在生成对称加密，也就是我们的AES,其实也就是相对于我们配置中的那个16的长度的加密key,生成了这个key之后我们就用公钥pubkey2进行加密，返回给客户端，因为只有客户端有pubkey2对应的私钥prikey2，只有客户端才能解密，客户端得到数据之后，用prikey2进行解密操作，得到AES的加密key,最后就用加密key进行数据传输的加密，至此整个流程结束。 spring-boot-starter-encrypt原理最后我们来简单的介绍下spring-boot-starter-encrypt的原理吧，也让大家能够理解为什么Spring Boot这么方便，只需要简单的配置一下就可以实现很多功能。 启动类上的@EnableEncrypt注解是用来开启功能的,通过@Import导入自动配置类12345678@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(&#123;EncryptAutoConfiguration.class&#125;)public @interface EnableEncrypt &#123;&#125; EncryptAutoConfiguration中配置请求和响应的处理类，用的是Spring中的RequestBodyAdvice和ResponseBodyAdvice，在Spring中对请求进行统计处理比较方便。如果还要更底层去封装那就要从servlet那块去处理了。123456789101112131415161718192021222324252627282930/** * 加解密自动配置 * */@Configuration@Component@EnableAutoConfiguration@EnableConfigurationProperties(EncryptProperties.class)public class EncryptAutoConfiguration &#123; /** * 配置请求解密 * @return */ @Bean public EncryptResponseBodyAdvice encryptResponseBodyAdvice() &#123; return new EncryptResponseBodyAdvice(); &#125; /** * 配置请求加密 * @return */ @Bean public EncryptRequestBodyAdvice encryptRequestBodyAdvice() &#123; return new EncryptRequestBodyAdvice(); &#125;&#125; 通过RequestBodyAdvice和ResponseBodyAdvice就可以对请求响应做处理了，大概的原理就是这么多了。 参考 http://cxytiandi.com/blog/detail/20235]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>前后端</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之-工厂模式]]></title>
    <url>%2F2019%2F06%2F11%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B-%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基本概念工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 介绍意图：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。 主要解决：主要解决接口选择的问题。 何时使用：我们明确地计划不同条件下创建不同实例时。 如何解决：让其子类实现工厂接口，返回的也是一个抽象的产品。 关键代码：创建过程在其子类执行。 应用实例： 1、您需要一辆汽车，可以直接从工厂里面提货，而不用去管这辆汽车是怎么做出来的，以及这个汽车里面的具体实现。 2、Hibernate 换数据库只需换方言和驱动就可以。 优点： 1、一个调用者想创建一个对象，只要知道其名称就可以了。 2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。 缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。 使用场景： 1、日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 2、数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 3、设计一个连接服务器的框架，需要三个协议，”POP3”、”IMAP”、”HTTP”，可以把这三个作为产品类，共同实现一个接口。 注意事项：作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。 实现我们将创建一个 Shape 接口和实现 Shape 接口的实体类。下一步是定义工厂类 ShapeFactory。FactoryPatternDemo，我们的演示类使用 ShapeFactory 来获取 Shape 对象。它将向 ShapeFactory 传递信息（CIRCLE / RECTANGLE / SQUARE），以便获取它所需对象的类型。 步骤 1创建一个接口: Shape.java 123public interface Shape &#123; void draw();&#125; 步骤 2创建实现接口的实体类。 Rectangle.java 1234567public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println("Inside Rectangle::draw() method."); &#125;&#125; Square.java1234567public class Square implements Shape &#123; @Override public void draw() &#123; System.out.println("Inside Square::draw() method."); &#125;&#125; Circle.java1234567public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Inside Circle::draw() method.&quot;); &#125;&#125; 步骤 3创建一个工厂，生成基于给定信息的实体类的对象。 ShapeFactory.java1234567891011121314151617public class ShapeFactory &#123; //使用 getShape 方法获取形状类型的对象 public Shape getShape(String shapeType)&#123; if(shapeType == null)&#123; return null; &#125; if(shapeType.equalsIgnoreCase("CIRCLE"))&#123; return new Circle(); &#125; else if(shapeType.equalsIgnoreCase("RECTANGLE"))&#123; return new Rectangle(); &#125; else if(shapeType.equalsIgnoreCase("SQUARE"))&#123; return new Square(); &#125; return null; &#125;&#125; 步骤 4使用该工厂，通过传递类型信息来获取实体类的对象。 FactoryPatternDemo.java123456789101112131415161718192021222324public class FactoryPatternDemo &#123; public static void main(String[] args) &#123; ShapeFactory shapeFactory = new ShapeFactory(); //获取 Circle 的对象，并调用它的 draw 方法 Shape shape1 = shapeFactory.getShape("CIRCLE"); //调用 Circle 的 draw 方法 shape1.draw(); //获取 Rectangle 的对象，并调用它的 draw 方法 Shape shape2 = shapeFactory.getShape("RECTANGLE"); //调用 Rectangle 的 draw 方法 shape2.draw(); //获取 Square 的对象，并调用它的 draw 方法 Shape shape3 = shapeFactory.getShape("SQUARE"); //调用 Square 的 draw 方法 shape3.draw(); &#125;&#125; 步骤 5执行程序，输出结果：123Inside Circle::draw() method.Inside Rectangle::draw() method.Inside Square::draw() method. 参考 http://www.runoob.com/design-pattern/factory-pattern.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>工厂模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之-装饰器模式]]></title>
    <url>%2F2019%2F06%2F11%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B-%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基本概念 装饰器模式，顾名思义起的是装饰的作用，就是在一个类上增加功能。如果通过继承来增加功能，在不修改代码的情况下，如果增加功能多的话，会使类的数量爆炸式增长，为管理带来巨大的麻烦。装饰器模式就比较好地解决了这一点。 介绍以下为装饰器模式的通用类图: Component，一般是接口或者抽象类，定义了最简单的方法，装饰器类和被装饰类都要实现该接口。 ConcreteComponent，被装饰类，实现了Component。 Decorator，装饰器类，通过该类为ConcreteComponent动态添加额外的方法，实现了Component接口，并且该对象中持有一个Component的成员变量。 ConcreteDecoratorA，ConcreteDecoratorB，具体的装饰类，该类中的方法就是要为ConcreteComponent动态添加的方法。 实现我们以生产一件衣服为例，生产一件衣服本身是个很简单的过程，一块布料裁剪好了之后做出衣服的样子就可以了，但是这样的衣服是卖不出去的，因为毫无美感，我们需要通过一些装饰来使衣服变得好看。但是时代在变化，人们的审美也在变化，装饰总是不断在变的，所以我们就要有一个灵活机动的模式来修改装饰。 Clothes.java123public interface Clothes &#123; public void makeClothes();&#125; MakeClothes.java12345678public class MakeClothes implements Clothes &#123; @Override public void makeClothes() &#123; System.out.println("制作一件衣服"); &#125;&#125; 步骤 3创建装饰器。 OperationSubstract.java 123456public class OperationSubstract implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 - num2; &#125;&#125; 话不多说，先来个衣服的最初成品，就是毫无美感的那种，那么如果现在要增加装饰，可以用一个类继承MakeClothes，然后增加里面makeClothes()方法，但是如果过几天装饰就变了，那么又要改动代码，而且如果装饰过多，这个类就显得很庞杂，不好维护，这个时候装饰器模式就来大显身手了。 Decorator.java1234567891011public class Decorator implements Clothes &#123; private Clothes clothes; public Decorator(Clothes _clothes) &#123; this.clothes = _clothes; &#125; @Override public void makeClothes() &#123; clothes.makeClothes(); &#125;&#125; 这就是一个装饰器，它有一个构造函数，参数是一个衣服类，同时它重载了makeClothes()方法，以便它的子类对其进行修改。下面是两个子类，分别对衣服进行了绣花和镂空 Embroidery.java1234567891011121314public class Embroidery extends Decorator &#123; public Embroidery(Clothes _clothes) &#123; super(_clothes); &#125; public void embroidery() &#123; System.out.println("给衣服绣花"); &#125; @Override public void makeClothes() &#123; super.makeClothes(); this.embroidery(); &#125;&#125; Hollow.java1234567891011121314public class Hollow extends Decorator &#123; public Hollow(Clothes _clothes) &#123; super(_clothes); &#125; public void hollow() &#123; System.out.println("关键位置镂空"); &#125; @Override public void makeClothes() &#123; super.makeClothes(); this.hollow(); &#125;&#125; 这两个子类的构造器都传入一个衣服模型，而且两个子类分别有各自的方法——绣花和镂空，但是他们均重写了makeClothes()方法，在制作衣服的过程中加入了绣花和镂空的操作，这样一来，我们只需要增删改这几个装饰器的子类，就可以完成各种不同的装饰，简洁明了，一目了然。下面测试一下： DecoratorDemo.java12345678910public class DecoratorDemo &#123; public static void main(String[] args) &#123; Clothes clothes = new MakeClothes(); clothes = new Embroidery(clothes); clothes = new Hollow(clothes); clothes.makeClothes(); System.out.println("衣服做好了"); &#125;&#125; 执行程序，输出结果：1234制作一件衣服给衣服绣花关键位置镂空衣服做好了 参考 https://www.cnblogs.com/fengshenjingjun/p/8343655.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>装饰器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之-策略模式]]></title>
    <url>%2F2019%2F06%2F11%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基本概念 在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 介绍意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。主要解决：在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。何时使用：一个系统有许多许多类，而区分它们的只是他们直接的行为。如何解决：将这些算法封装成一个一个的类，任意地替换。关键代码：实现同一个接口。应用实例： 1、诸葛亮的锦囊妙计，每一个锦囊就是一个策略。 2、旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略。 3、JAVA AWT 中的 LayoutManager。优点： 1、算法可以自由切换。 2、避免使用多重条件判断。 3、扩展性良好。缺点： 1、策略类会增多。 2、所有策略类都需要对外暴露。使用场景： 1、如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 2、一个系统需要动态地在几种算法中选择一种。 3、如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。注意事项：如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。 实现我们将创建一个定义活动的 Strategy 接口和实现了 Strategy 接口的实体策略类。Context 是一个使用了某种策略的类。StrategyPatternDemo，我们的演示类使用 Context 和策略对象来演示 Context 在它所配置或使用的策略改变时的行为变化。 步骤 1创建一个接口。 Strategy.java123public interface Strategy &#123; public int doOperation(int num1, int num2);&#125; 步骤 2创建实现接口的实体类。 OperationAdd.java 123456public class OperationAdd implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 + num2; &#125;&#125; OperationSubstract.java123456public class OperationSubstract implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 - num2; &#125;&#125; OperationMultiply.java123456public class OperationMultiply implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 * num2; &#125;&#125; 步骤 3创建 Context 类。 Context.java 1234567891011public class Context &#123; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeStrategy(int num1, int num2)&#123; return strategy.doOperation(num1, num2); &#125;&#125; 步骤 4使用 Context 来查看当它改变策略 Strategy 时的行为变化。 StrategyPatternDemo.java 123456789101112public class StrategyPatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(new OperationAdd()); System.out.println("10 + 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationSubstract()); System.out.println("10 - 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationMultiply()); System.out.println("10 * 5 = " + context.executeStrategy(10, 5)); &#125;&#125; 步骤 5执行程序，输出结果：12310 + 5 = 1510 - 5 = 510 * 5 = 50 参考 http://www.runoob.com/design-pattern/strategy-pattern.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>策略模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之-观察者模式]]></title>
    <url>%2F2019%2F06%2F11%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基本概念 观察者模式中，一个被观察者管理所有相依于它的观察者物件，并且在本身的状态改变时主动发出通知。这通常通过呼叫各观察者所提供的方法来实现。此种模式通常被用来实现事件处理系统。 角色 抽象被观察者角色：把所有对观察者对象的引用保存在一个集合中，每个被观察者角色都可以有任意数量的观察者。被观察者提供一个接口，可以增加和删除观察者角色。一般用一个抽象类和接口来实现。 抽象观察者角色：为所有具体的观察者定义一个接口，在得到主题的通知时更新自己。 具体被观察者角色：在被观察者内部状态改变时，给所有登记过的观察者发出通知。具体被观察者角色通常用一个子类实现。 具体观察者角色：该角色实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态相协调。通常用一个子类实现。如果需要，具体观察者角色可以保存一个指向具体主题角色的引用。 适用场景 1) 当一个抽象模型有两个方面, 其中一个方面依赖于另一方面。将这二者封装在独立的对象中以使它们可以各自独立地改变和复用。 2) 当对一个对象的改变需要同时改变其它对象, 而不知道具体有多少对象有待改变。 3) 当一个对象必须通知其它对象，而它又不能假定其它对象是谁。换言之, 你不希望这些对象是紧密耦合的。 应用珠宝商运送一批钻石，有黄金强盗准备抢劫，珠宝商雇佣了私人保镖，警察局也派人护送，于是当运输车上路的时候，强盗保镖警察都要观察运输车一举一动， 抽象的观察者 1234public interface Watcher&#123; public void update();&#125; 抽象的被观察者，在其中声明方法（添加、移除观察者，通知观察者）： 12345678public interface Watched&#123; public void addWatcher(Watcher watcher); public void removeWatcher(Watcher watcher); public void notifyWatchers();&#125; 具体的观察者-保镖12345678public class Security implements Watcher&#123; @Override public void update() &#123; System.out.println(“运输车有行动，保安贴身保护"); &#125;&#125; 具体的观察者-强盗 12345678public class Thief implements Watcher&#123; @Override public void update() &#123; System.out.println(“运输车有行动，强盗准备动手"); &#125;&#125; 具体的观察者-警察 12345678public class Police implements Watcher&#123; @Override public void update() &#123; System.out.println(“运输车有行动，警察护航"); &#125;&#125; 具体的被观察者1234567891011121314151617181920212223242526public class Transporter implements Watched&#123; private List&lt;Watcher&gt; list = new ArrayList&lt;Watcher&gt;(); @Override public void addWatcher(Watcher watcher) &#123; list.add(watcher); &#125; @Override public void removeWatcher(Watcher watcher) &#123; list.remove(watcher); &#125; @Override public void notifyWatchers(String str) &#123; for (Watcher watcher : list) &#123; watcher.update(); &#125; &#125; &#125; 客户端1234567891011121314151617public class Test&#123; public static void main(String[] args) &#123; Transporter transporter = new Transporter(); Police police = new Police(); Security security = new Security(); Thief thief = new Thief(); transporter.addWatcher(police); transporter.addWatcher(security); transporter.addWatcher(security); transporter.notifyWatchers(); &#125;&#125; 小结 我推你拉 例子中没有关于数据和状态的变化通知，只是简单通知到各个观察者，告诉他们被观察者有行动。 观察者模式在关于目标角色、观察者角色通信的具体实现中，有两个版本。 一种情况便是目标角色在发生变化后，仅仅告诉观察者角色“我变化了”，观察者角色如果想要知道具体的变化细节，则就要自己从目标角色的接口中得到。这种模式被很形象的称为：拉模式——就是说变化的信息是观察者角色主动从目标角色中“拉”出来的。 还有一种方法，那就是我目标角色“服务一条龙”，通知你发生变化的同时，通过一个参数将变化的细节传递到观察者角色中去。这就是“推模式”——管你要不要，先给你啦。 这两种模式的使用，取决于系统设计时的需要。如果目标角色比较复杂，并且观察者角色进行更新时必须得到一些具体变化的信息，则“推模式”比较合适。如果目标角色比较简单，则“拉模式”就很合适啦。 参考 https://blog.csdn.net/jason0539/article/details/45055233]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>观察者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之-职责链模式]]></title>
    <url>%2F2019%2F06%2F11%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B-%E8%81%8C%E8%B4%A3%E9%93%BE%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基本概念 什么是链 链是一系列节点的集合。 链的各节点可灵活拆分再重组。 职责链模式 使多个对象都有机会处理请求，从而避免请求的发送者和接受者之间的耦合关系， 将这个对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理他为止。 角色 抽象处理者角色(Handler)：定义出一个处理请求的接口。如果需要，接口可以定义 出一个方法以设定和返回对下家的引用。这个角色通常由一个Java抽象类或者Java接口实现。 具体处理者角色(ConcreteHandler)：具体处理者接到请求后，可以选择将请求处理掉，或者将请求传给下家。由于具体处理者持有对下家的引用，因此，如果需要，具体处理者可以访问下家。 职责链灵活在哪 改变内部的传递规则在内部，项目经理完全可以跳过人事部到那一关直接找到总经理。每个人都可以去动态地指定他的继任者。 可以从职责链任何一关开始。如果项目经理不在，可以直接去找部门经理，责任链还会继续，没有影响。 用与不用的区别不用职责链的结构，我们需要和公司中的每一个层级都发生耦合关系。如果反映在代码上即使我们需要在一个类中去写上很多丑陋的if….else语句。如果用了职责链，相当于我们面对的是一个黑箱，我们只需要认识其中的一个部门，然后让黑箱内部去负责传递就好了 纯的与不纯的责任链模式一个纯的责任链模式要求一个具体的处理者对象只能在两个行为中选择一个：一是承担责任，而是把责任推给下家。不允许出现某一个具体处理者对象在承担了一部分责任后又 把责任向下传的情况。在一个纯的责任链模式里面，一个请求必须被某一个处理者对象所接收；在一个不纯的责任链模式里面，一个请求可以最终不被任何接收端对象所接收。纯的责任链模式的实际例子很难找到，一般看到的例子均是不纯的责任链模式的实现。 示例 代码1.抽象处理者角色123456789101112131415161718192021222324public abstract class Handler &#123; /** * 持有后继的责任对象 */ protected Handler successor; /** * 示意处理请求的方法，虽然这个示意方法是没有传入参数的 * 但实际是可以传入参数的，根据具体需要来选择是否传递参数 */ public abstract void handleRequest(); /** * 取值方法 */ public Handler getSuccessor() &#123; return successor; &#125; /** * 赋值方法，设置后继的责任对象 */ public void setSuccessor(Handler successor) &#123; this.successor = successor; &#125; &#125; 2.具体处理者角色12345678910111213141516171819202122public class ConcreteHandler extends Handler &#123; /** * 处理方法，调用此方法处理请求 */ @Override public void handleRequest() &#123; /** * 判断是否有后继的责任对象 * 如果有，就转发请求给后继的责任对象 * 如果没有，则处理请求 */ if(getSuccessor() != null) &#123; System.out.println("放过请求"); getSuccessor().handleRequest(); &#125;else &#123; System.out.println("处理请求"); &#125; &#125; &#125; 3.客户端类1234567891011public class Client &#123; public static void main(String[] args) &#123; //组装责任链 Handler handler1 = new ConcreteHandler(); Handler handler2 = new ConcreteHandler(); handler1.setSuccessor(handler2); //提交请求 handler1.handleRequest(); &#125;&#125; 说明可以看出，客户端创建了两个处理者对象，并指定第一个处理者对象的下家是第二个处理者对象，而第二个处理者对象没有下家。然后客户端将请求传递给第一个处理者对象。由于本示例的传递逻辑非常简单：只要有下家，就传给下家处理；如果没有下家，就自行处理。因此，第一个处理者对象接到请求后，会将请求传递给第二个处理者对象。由于第二个处理者对象没有下家，于是自行处理请求。活动时序图如下所示。 参考 https://blog.csdn.net/jason0539/article/details/45091639#]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>职责链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话设计模式]]></title>
    <url>%2F2019%2F06%2F11%2F%E5%A4%A7%E8%AF%9D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[介绍分类总体来说设计模式分为三大类： 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。其实还有两类：并发型模式和线程池模式。 中英文对照 中文 英文 1.工厂方法模式 Factory Method Pattern 2.抽象工厂模式 Abstract Factory Pattern 3.建造者模式 Builder Pattern 4.原型模式 Prototype Pattern 5.单例模式 Singleton Pattern 6.适配器模式 Adapter Pattern 7.桥梁模式/桥接模式 Bridge Pattern 8.组合模式 Composite Pattern 9.装饰模式 Decorator Pattern 10.门面模式/外观模式 Facade Pattern 11.享元模式 Flyweight Pattern 12.代理模式 Proxy pattern 13.责任链模式 Chain of Responsibility Pattern 14.命令模式 Command Pattern 15.解释器模式 Interpreter Pattern 16.迭代器模式 Iterator Pattern 17.中介者模式 Mediator Pattern 18.备忘录模式 Memento Pattern 19.观察者模式 Observer Pattern 20状态模式 State Pattern 21.策略模式 Strategy Pattern 22.模板方法模式 Template Method Pattern 23.访问者模式 Visitor Pattern 参考 http://www.runoob.com/design-pattern/design-pattern-intro.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工具类🔧-Fastjson进阶使用]]></title>
    <url>%2F2019%2F06%2F10%2F%E5%B7%A5%E5%85%B7%E7%B1%BB%F0%9F%94%A7-Fastjson%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[fastjson用于将Java Bean序列化为JSON字符串，也可以从JSON字符串反序列化到JavaBean。主要就以下几点做个介绍 SerializerFeature特性的使用 JSONField与JSONType注解的使用 SerializeFilter 泛型反序列化 fastjson各种概念 简单使用 通过maven引入相应的json包 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.58&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 定义一个需要转换所实体类User，代码如下： 12345678910111213141516171819package com.ohaotian.feifz.style.study.utils.fastjson;/** * @author feifz * @version 1.0.0 * @Description 研究fastjson用到的对象 * @createTime 2019年06月10日 16:36:00 */import com.alibaba.fastjson.annotation.JSONField;import lombok.Data;import java.util.Date;@Datapublic class User &#123; private Long id; private String name; @JSONField(format = "yyyy-MM-dd HH:mm:ss") private Date createTime;&#125; 写个简单的测试类用于测试fastjson的序列化与反序列化，代码如下： 123456789101112131415161718192021222324252627282930313233343536package com.ohaotian.feifz.style.study.utils.fastjson;/** * @author feifz * @version 1.0.0 * @Description fastjson简单使用 * @createTime 2019年06月10日 16:37:00 */import com.alibaba.fastjson.JSON;import java.util.Date;public class SimpleTest &#123; public static void main(String[] args) &#123; serialize(); deserialize(); &#125; public static void serialize() &#123; User user = new User(); user.setId(11L); user.setName("西安"); user.setCreateTime(new Date()); String jsonString = JSON.toJSONString(user, true); System.out.println(jsonString); &#125; public static void deserialize() &#123; String jsonString = "&#123;\"createTime\":\"2018-08-17 14:38:38\",\"id\":11,\"name\":\"西安\"&#125;"; User user = JSON.parseObject(jsonString, User.class); System.out.println(user.getName()); System.out.println(user.getCreateTime()); &#125;&#125; SerializerFeature特性的使用 fastjson通过SerializerFeature对生成的json格式的数据进行一些定制，比如可以输入的格式更好看，使用单引号而非双引号等。例子程序如下：123456789101112131415161718192021222324252627package com.ohaotian.feifz.style.study.utils.fastjson;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.serializer.SerializerFeature;import java.util.Date;/** * @author feifz * @version 1.0.0 * @Description SerializerFeature特性的使用 * @createTime 2019年06月10日 16:40:00 */public class SerializerFeatureTest &#123; public static void main(String[] args) &#123; User user = new User(); user.setId(11L); user.setCreateTime(new Date()); String jsonString = JSON.toJSONString(user, SerializerFeature.PrettyFormat, SerializerFeature.WriteNullStringAsEmpty, SerializerFeature.UseSingleQuotes); System.out.println(jsonString); &#125;&#125; 输出的结果如下：12345&#123; 'createTime':'2019-06-10 17:25:34', 'id':11, 'name':''&#125; SerializerFeature常用属性 名称 含义 QuoteFieldNames 输出key时是否使用双引号,默认为true UseSingleQuotes 使用单引号而不是双引号,默认为false WriteMapNullValue 是否输出值为null的字段,默认为false WriteEnumUsingToString Enum输出name()或者original,默认为false UseISO8601DateFormat Date使用ISO8601格式输出，默认为false WriteNullListAsEmpty List字段如果为null,输出为[],而非null WriteNullStringAsEmpty 字符类型字段如果为null,输出为”“,而非null WriteNullNumberAsZero 数值字段如果为null,输出为0,而非null WriteNullBooleanAsFalse Boolean字段如果为null,输出为false,而非null SkipTransientField 如果是true，类中的Get方法对应的Field是transient，序列化时将会被忽略。默认为true SortField 按字段名称排序后输出。默认为false WriteTabAsSpecial 把\t做转义输出，默认为false不推荐设为true PrettyFormat 结果是否格式化,默认为false WriteClassName 序列化时写入类型信息，默认为false。反序列化是需用到 DisableCircularReferenceDetect 消除对同一对象循环引用的问题，默认为false WriteSlashAsSpecial 对斜杠’/’进行转义 BrowserCompatible 将中文都会序列化为\uXXXX格式，字节数会多一些，但是能兼容IE 6，默认为false WriteDateUseDateFormat 全局修改日期格式,默认为false。 DisableCheckSpecialChar 一个对象的字符串属性中如果有特殊字符如双引号，将会在转成json时带有反斜杠转移符。如果不需要转义，可以使用这个属性。默认为false BeanToArray 将对象转为array输出 JSONField与JSONType注解的使用 注意和@JSONField不同的是,@JSONType是配置在类上的，而@JSONField是配置在字段和方法上的。 JSONField注解的使用 fastjson提供了JSONField对序列化与反序列化进行定制，比如可以指定字段的名称，序列化的顺序。JSONField用于属性，方法方法参数上。JSONField的源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940package com.alibaba.fastjson.annotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import com.alibaba.fastjson.parser.Feature;import com.alibaba.fastjson.serializer.SerializerFeature;@Retention(RetentionPolicy.RUNTIME)@Target(&#123; ElementType.METHOD, ElementType.FIELD, ElementType.PARAMETER &#125;)public @interface JSONField &#123;// 配置序列化和反序列化的顺序 int ordinal() default 0;// 指定字段的名称 String name() default "";// 指定字段的格式，对日期格式有用 String format() default ""; // 是否序列化 boolean serialize() default true;// 是否反序列化 boolean deserialize() default true;//字段级别的SerializerFeature SerializerFeature[] serialzeFeatures() default &#123;&#125;;// Feature[] parseFeatures() default &#123;&#125;; //给属性打上标签， 相当于给属性进行了分组 String label() default ""; boolean jsonDirect() default false; //制定属性的序列化类 Class&lt;?&gt; serializeUsing() default Void.class; //制定属性的反序列化类 Class&lt;?&gt; deserializeUsing() default Void.class; String[] alternateNames() default &#123;&#125;; boolean unwrapped() default false;&#125; 属性name通过在注解@JSONField指定属性name可以指定该属性在序列化和反序列化过程中输出的key。可作用于Field上，也可作用于setter和setter方法上。一、作用Field （相当于get set的总和）@JSONField作用在Field时，其name不仅定义了输入key的名称，同时也定义了输出的名称。二、作用在setter和getter方法上顾名思义，当作用在setter方法上时，就相当于根据name到json中寻找对应的值，并调用该setter对象赋值。当作用在getter上时，在bean转换为json时，其key值为name定义的值。示例如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.ohaotian.feifz.style.study.utils.fastjson;/** * @author feifz * @version 1.0.0 * @Description JSONField注解 name属性用法 * @createTime 2019年06月11日 14:00:00 */import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.annotation.JSONField;public class JsonFieldNameDemo &#123; @JSONField(name = "jsonName") private String name; private String age; private String email; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @JSONField(name = "jsonAge") public String getAge() &#123; return age; &#125; @JSONField(name = "jsonAge") public void setAge(String age) &#123; this.age = age; &#125; public String getEmail() &#123; return email; &#125; @JSONField(name = "jsonEmail") public void setEmail(String email) &#123; this.email = email; &#125; @Override public String toString() &#123; return "JsonFieldNameDemo [name=" + name + ", age=" + age + ", email=" + email + "]"; &#125; public static void main(String[] args) &#123; JsonFieldNameDemo jsonFieldNameDemo = new JsonFieldNameDemo(); jsonFieldNameDemo.setAge("21岁"); jsonFieldNameDemo.setEmail("111@11.com"); jsonFieldNameDemo.setName("hhh"); System.out.println(JSON.toJSONString(jsonFieldNameDemo)); //输出了：&#123;"jsonName":"hhh","jsonAge":"21岁","email":"111@11.com"&#125; String json = "&#123;\"email\":\"111@11.com\",\"jsonAge\":\"21岁\",\"jsonName\":\"hhh\"&#125;"; JsonFieldNameDemo jsonTest = JSON.parseObject(json, JsonFieldNameDemo.class); System.out.println(jsonTest.toString()); &#125;&#125; 输出结果如下：12&#123;"email":"111@11.com","jsonAge":"21岁","jsonName":"hhh"&#125;JsonFieldNameDemo [name=hhh, age=21岁, email=null] serialize，deserializeserialize：是否序列化，默认值都为true，指定为false时序列化过程中不序列化该字段。deserialize：是否反序列化，默认值都为true，指定为false时反序列化过程中不反序列化该字段示例代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.ohaotian.feifz.style.study.utils.fastjson;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.annotation.JSONField;/** * @author feifz * @version 1.0.0 * @Description @JSONField name属性示例 * @createTime 2019年06月11日 14:09:00 */public class JsonFieldNameDemo &#123; private String name; @JSONField(deserialize = false) private String age; @JSONField(serialize = false) private String email; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getAge() &#123; return age; &#125; public void setAge(String age) &#123; this.age = age; &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; @Override public String toString() &#123; return "JsonFieldNameDemo&#123;" + "name='" + name + '\'' + ", age='" + age + '\'' + ", email='" + email + '\'' + '&#125;'; &#125; public static void main(String[] args) &#123; JsonFieldNameDemo jsonFieldNameTest1 = new JsonFieldNameDemo(); jsonFieldNameTest1.setAge("18"); jsonFieldNameTest1.setEmail("123@163.com"); jsonFieldNameTest1.setName("Bob"); System.out.println(JSON.toJSONString(jsonFieldNameTest1)); String json = "&#123;\"age\":\"18\",\"email\":\"123@163.com\",\"name\":\"Bob\"&#125;"; JsonFieldNameDemo jsonFieldNameTest2 = JSON.parseObject(json, JsonFieldNameDemo.class); System.out.println(jsonFieldNameTest2.toString()); &#125;&#125; 输出结果如下：12&#123;"age":"18","name":"Bob"&#125;JsonFieldNameDemo&#123;name='Bob', age='null', email='123@163.com'&#125; serializeUsing，deserializeUsing其中serializeUsing与deserializeUsing可以用于对字段的序列化与反序列化进行定制化。比如我们在User实体上加上个sex属性，类型为boolean。下面分别定义了序列化类与反序列化类。序列化类代码如下： 123456789101112131415161718192021222324252627282930313233package com.ohaotian.feifz.style.study.utils.fastjson;/** * @author feifz * @version 1.0.0 * @Description TODO * @createTime 2019年06月11日 10:23:00 */import com.alibaba.fastjson.serializer.JSONSerializer;import com.alibaba.fastjson.serializer.ObjectSerializer;import java.io.IOException;import java.lang.reflect.Type;public class SexSerializer implements ObjectSerializer &#123; @Override public void write(JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) throws IOException &#123; Boolean value = (Boolean) object; String text = "女"; if (value != null &amp;&amp; value == true) &#123; text = "男"; &#125; serializer.write(text); &#125;&#125; 反序列化类代码如下：12345678910111213141516171819202122232425262728293031323334353637package com.ohaotian.feifz.style.study.utils.fastjson;/** * @author feifz * @version 1.0.0 * @Description TODO * @createTime 2019年06月11日 10:24:00 */import com.alibaba.fastjson.parser.DefaultJSONParser;import com.alibaba.fastjson.parser.JSONToken;import com.alibaba.fastjson.parser.deserializer.ObjectDeserializer;import java.lang.reflect.Type;public class SexDeserialize implements ObjectDeserializer &#123; @Override public &lt;T&gt; T deserialze(DefaultJSONParser parser, Type type, Object fieldName) &#123; String sex = parser.parseObject(String.class); if ("男".equals(sex)) &#123; return (T) Boolean.TRUE; &#125; else &#123; return (T) Boolean.FALSE; &#125; &#125; @Override public int getFastMatchToken() &#123; return JSONToken.UNDEFINED; &#125;&#125; 在定义bean对象时在字段sex上加上注解如下：12345678910111213141516171819202122232425262728package com.ohaotian.feifz.style.study.utils.fastjson;/** * @author feifz * @version 1.0.0 * @Description 研究fastjson用到的对象 * @createTime 2019年06月10日 16:36:00 */import com.alibaba.fastjson.annotation.JSONField;import lombok.Data;import java.util.Date;@Datapublic class User &#123; private Long id; private String name; @JSONField(format = "yyyy-MM-dd HH:mm:ss") private Date createTime; @JSONField(serializeUsing = SexSerializer.class, deserializeUsing = SexDeserialize.class) private Boolean sex;&#125; 这样在执行下面代码之后就会发现对sex字段的值定制化了1234567891011121314151617181920212223242526272829303132333435363738package com.ohaotian.feifz.style.study.utils.fastjson;/** * @author feifz * @version 1.0.0 * @Description fastjson简单使用 * @createTime 2019年06月10日 16:37:00 */import com.alibaba.fastjson.JSON;import java.util.Date;public class SimpleTest &#123; public static void main(String[] args) &#123; serialize(); deserialize(); &#125; public static void serialize() &#123; User user = new User(); user.setId(11L); user.setName("西安"); user.setSex(false); user.setCreateTime(new Date()); String jsonString = JSON.toJSONString(user, true); System.out.println(jsonString); &#125; public static void deserialize() &#123; String jsonString = "&#123;\"createTime\":\"2018-08-17 14:38:38\",\"id\":11,\"name\":\"西安\",\"sex\":\"男\"&#125;"; User user = JSON.parseObject(jsonString, User.class); System.out.println(user.getSex()); System.out.println(user.getName()); System.out.println(user.getCreateTime()); &#125;&#125; 输出的结果如下：123456789&#123; "createTime":"2019-06-11 11:20:08", "id":11, "name":"西安", "sex":"女"&#125;true西安Fri Aug 17 14:38:38 CST 2018 JSONType注解的使用 fastjosn提供了JSONType用于类级别的定制化, JSONType的源码如下： 源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.alibaba.fastjson.annotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import com.alibaba.fastjson.PropertyNamingStrategy;import com.alibaba.fastjson.parser.Feature;import com.alibaba.fastjson.serializer.SerializeFilter;import com.alibaba.fastjson.serializer.SerializerFeature;@Retention(RetentionPolicy.RUNTIME)//需要标注在类上@Target(&#123; ElementType.TYPE &#125;)public @interface JSONType &#123; boolean asm() default true;//这里可以定义输出json的字段顺序 String[] orders() default &#123;&#125;;//包含的字段 String[] includes() default &#123;&#125;;//不包含的字段 String[] ignores() default &#123;&#125;;//类级别的序列化特性定义 SerializerFeature[] serialzeFeatures() default &#123;&#125;; Feature[] parseFeatures() default &#123;&#125;; //按字母顺序进行输出 boolean alphabetic() default true; Class&lt;?&gt; mappingTo() default Void.class; Class&lt;?&gt; builder() default Void.class; String typeName() default ""; String typeKey() default ""; Class&lt;?&gt;[] seeAlso() default&#123;&#125;; //序列化类 Class&lt;?&gt; serializer() default Void.class; //反序列化类 Class&lt;?&gt; deserializer() default Void.class; boolean serializeEnumAsJavaBean() default false; PropertyNamingStrategy naming() default PropertyNamingStrategy.CamelCase; Class&lt;? extends SerializeFilter&gt;[] serialzeFilters() default &#123;&#125;;&#125; 属性 includes序列化时，只序列化这些字段使用示例：@JSONType(includes = {“name”,”age”}) ignores序列化时，忽略这些字段使用示例：@JSONType(ignores = {“email”}) orders序列化时，按照指定的顺序输出结果使用示例：@JSONType(orders = {“name”,”age”}) 使用示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package com.ohaotian.feifz.style.study.utils.fastjson;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.annotation.JSONType;/** * @author feifz * @version 1.0.0 * @Description @JSONType 注解使用示例 * @createTime 2019年06月11日 14:41:00 */@JSONType(includes = &#123;"name","age"&#125;,ignores = &#123;"email"&#125;,orders = &#123;"name","age"&#125;)public class JsonTypeDemo &#123; private String name; private String age; private String email; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getAge() &#123; return age; &#125; public void setAge(String age) &#123; this.age = age; &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; public JsonTypeDemo(String name, String age, String email) &#123; this.name = name; this.age = age; this.email = email; &#125; @Override public String toString() &#123; return "JsonTypeDemo&#123;" + "name='" + name + '\'' + ", age='" + age + '\'' + ", email='" + email + '\'' + '&#125;'; &#125; public static void main(String[] args) &#123; JsonTypeDemo demo = new JsonTypeDemo("Mary","17","123@163.com"); System.out.println(JSON.toJSONString(demo)); String json = "&#123;\"age\":\"17\",\"email\":\"123@163.com\",\"name\":\"Mary\"&#125;"; JsonTypeDemo jsonTypeDemo = JSON.parseObject(json,JsonTypeDemo.class); System.out.println(jsonTypeDemo.toString()); &#125;&#125; 输出结果如下：12&#123;"name":"Mary","age":"17"&#125;JsonTypeDemo&#123;name='Mary', age='17', email='123@163.com'&#125; SerializeFilter泛型反序列化12345678910111213141516171819202122232425262728293031323334353637383940414243444546```# fastjson各种概念* JSON：本身是Abstract，提供了一系统的工具方法方便用户使用的API。## 序列化相关的概念* SerializeConfig：内部是个map容器主要功能是配置并记录每种Java类型对应的序列化类。* SerializeWriter 继承自Java的Writer，其实就是个转为FastJSON而生的StringBuilder，完成高性能的字符串拼接。* SerializeFilter: 用于对对象的序列化实现各种定制化的需求。* SerializerFeature：对于对输出的json做各种格式化的需求。* JSONSerializer：相当于一个序列化组合器，集成了*SerializeConfig， SerializeWriter ， SerializeFilter与SerializerFeature。序列化的入口代码如下，上面提到的各种概念都包含了：``` java/** * @since 1.2.9 * @return */ public static String toJSONString(Object object, // SerializeConfig config, // SerializeFilter[] filters, // String dateFormat, // int defaultFeatures, // SerializerFeature... features) &#123; SerializeWriter out = new SerializeWriter(null, defaultFeatures, features); try &#123; JSONSerializer serializer = new JSONSerializer(out, config); if (dateFormat != null &amp;&amp; dateFormat.length() != 0) &#123; serializer.setDateFormat(dateFormat); serializer.config(SerializerFeature.WriteDateUseDateFormat, true); &#125; if (filters != null) &#123; for (SerializeFilter filter : filters) &#123; serializer.addFilter(filter); &#125; &#125; serializer.write(object); return out.toString(); &#125; finally &#123; out.close(); &#125; &#125; 反序列化相关的概念ParserConfig：内部通过一个map保存各种ObjectDeserializer。JSONLexer : 与SerializeWriter相对应，用于解析json字符串。JSONToken：定义了一系统的特殊字符，这些称为token。ParseProcess ：定制反序列化，类似于SerializeFilter。Feature：用于定制各种反序列化的特性。DefaultJSONParser：相当于反序列化组合器，集成了ParserConfig，Feature， JSONLexer 与ParseProcess。反序列化的入口代码如下，上面的概念基本都包含了：12345678910111213141516171819202122232425262728293031323334353637@SuppressWarnings("unchecked") public static &lt;T&gt; T parseObject(String input, Type clazz, ParserConfig config, ParseProcess processor, int featureValues, Feature... features) &#123; if (input == null) &#123; return null; &#125; if (features != null) &#123; for (Feature feature : features) &#123; featureValues |= feature.mask; &#125; &#125; DefaultJSONParser parser = new DefaultJSONParser(input, config, featureValues); if (processor != null) &#123; if (processor instanceof ExtraTypeProvider) &#123; parser.getExtraTypeProviders().add((ExtraTypeProvider) processor); &#125; if (processor instanceof ExtraProcessor) &#123; parser.getExtraProcessors().add((ExtraProcessor) processor); &#125; if (processor instanceof FieldTypeResolver) &#123; parser.setFieldTypeResolver((FieldTypeResolver) processor); &#125; &#125; T value = (T) parser.parseObject(clazz, null); parser.handleResovleTask(value); parser.close(); return (T) value; &#125; 参考 https://www.jianshu.com/p/eaeaa5dce258]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>fastjson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工具类🔧-Fastjson入门使用]]></title>
    <url>%2F2019%2F06%2F10%2F%E5%B7%A5%E5%85%B7%E7%B1%BB%F0%9F%94%A7-Fastjson%2F</url>
    <content type="text"><![CDATA[简介什么是Fastjson?fastjson是阿里巴巴的开源JSON解析库，它可以解析JSON格式的字符串，支持将Java Bean序列化为JSON字符串，也可以从JSON字符串反序列化到JavaBean。Fastjson是一个Java语言编写的高性能功能完善的JSON库。它采用一种“假定有序快速匹配”的算法，把JSON Parse的性能提升到极致，是目前Java语言中最快的JSON库。Fastjson接口简单易用，已经被广泛使用在缓存序列化、协议交互、Web输出、Android客户端等多种应用场景。主要特点：快速FAST (比其它任何基于Java的解析器和生成器更快，包括jackson）强大（支持普通JDK类包括任意Java Bean Class、Collection、Map、Date或enum）零依赖（没有依赖其它任何类库除了JDK）开源，使用Apache License 2.0协议开源。源码：https://github.com/alibaba/fastjsonwiki：https://github.com/alibaba/fastjson/wiki/Quick-Start-CN Fastjson使用场景fastjson已经被广泛使用在各种场景，包括cache存储、RPC通讯、MQ通讯、网络协议通讯、Android客户端、Ajax服务器处理程序等等。 Fastjson的优点 速度快fastjson相对其他JSON库的特点是快，从2011年fastjson发布1.1.x版本之后，其性能从未被其他Java实现的JSON库超越。 使用广泛fastjson在阿里巴巴大规模使用，在数万台服务器上部署，fastjson在业界被广泛接受。在2012年被开源中国评选为最受欢迎的国产开源软件之一。 测试完备fastjson有非常多的testcase，在1.2.11版本中，testcase超过3321个。每次发布都会进行回归测试，保证质量稳定。 使用简单fastjson的API十分简洁。 12String text = JSON.toJSONString(obj); //序列化Model vo = JSON.parseObject("&#123;...&#125;", Mpode.class); //反序列化 功能完备支持泛型，支持流处理超大文本，支持枚举，支持序列化和反序列化扩展。 下载和使用下载你可以在maven中央仓库中直接下载：1http://repo1.maven.org/maven2/com/alibaba/fastjson/ 或者配置maven依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;x.x.x&lt;/version&gt;&lt;/dependency&gt; 其中x.x.x是版本号，跟进需要使用特定版本，建议使用最新版本,目前最新版本为1.2.58 简单使用 JSON这个类是fastjson API的入口，主要的功能都通过这个类提供。序列化API 123456789101112131415package com.alibaba.fastjson;public abstract class JSON &#123; // 将Java对象序列化为JSON字符串，支持各种各种Java基本类型和JavaBean public static String toJSONString(Object object, SerializerFeature... features); // 将Java对象序列化为JSON字符串，返回JSON字符串的utf-8 bytes public static byte[] toJSONBytes(Object object, SerializerFeature... features); // 将Java对象序列化为JSON字符串，写入到Writer中 public static void writeJSONString(Writer writer, Object object, SerializerFeature... features); // 将Java对象序列化为JSON字符串，按UTF-8编码写入到OutputStream中 public static final int writeJSONString(OutputStream os, // Object object, // SerializerFeature... features);&#125; JSON字符串反序列化API 1234567891011121314151617package com.alibaba.fastjson;public abstract class JSON &#123; // 将JSON字符串反序列化为JavaBean public static &lt;T&gt; T parseObject(String jsonStr, Class&lt;T&gt; clazz, Feature... features); // 将JSON字符串反序列化为JavaBean public static &lt;T&gt; T parseObject(byte[] jsonBytes, // UTF-8格式的JSON字符串 Class&lt;T&gt; clazz, Feature... features); // 将JSON字符串反序列化为泛型类型的JavaBean public static &lt;T&gt; T parseObject(String text, TypeReference&lt;T&gt; type, Feature... features); // 将JSON字符串反序列为JSONObject public static JSONObject parseObject(String text);&#125; 简单示例parse Tree12import com.alibaba.fastjson.*;JSONObject jsonObj = JSON.parseObject(jsonStr); parse POJO12import com.alibaba.fastjson.JSON;Model model = JSON.parseObject(jsonStr, Model.class); parse POJO Generic123import com.alibaba.fastjson.JSON;Type type = new TypeReference&lt;List&lt;Model&gt;&gt;() &#123;&#125;.getType(); List&lt;Model&gt; list = JSON.parseObject(jsonStr, type); convert POJO to json string123import com.alibaba.fastjson.JSON;Model model = ...; String jsonStr = JSON.toJSONString(model); convert POJO to json bytes123import com.alibaba.fastjson.JSON;Model model = ...; byte[] jsonBytes = JSON.toJSONBytes(model); write POJO as json string to OutputStream1234import com.alibaba.fastjson.JSON;Model model = ...; OutputStream os;JSON.writeJSONString(os, model); write POJO as json string to Writer1234import com.alibaba.fastjson.JSON;Model model = ...; Writer writer = ...;JSON.writeJSONString(writer, model); 高级使用Fastjson 定制序列化 简介 fastjson支持多种方式定制序列化。通过@JSONField定制序列化通过@JSONType定制序列化通过SerializeFilter定制序列化通过ParseProcess定制反序列化 使用@JSONField配置 可以把@JSONField配置在字段或者getter/setter方法上。例如：1234public class VO &#123; @JSONField(name="ID") private int id; &#125; 或者123456789public class VO &#123; private int id; @JSONField(name="ID") public int getId() &#123; return id;&#125; @JSONField(name="ID") public void setId(int value) &#123;this.id = id;&#125;&#125; 使用@JSONType配置和JSONField类似，但JSONType配置在类上，而不是field或者getter/setter方法上。 通过SerializeFilter定制序列化通过SerializeFilter可以使用扩展编程的方式实现定制序列化。fastjson提供了多种SerializeFilter： PropertyPreFilter 根据PropertyName判断是否序列化 PropertyFilter 根据PropertyName和PropertyValue来判断是否序列化 NameFilter 修改Key，如果需要修改Key,process返回值则可 ValueFilter 修改Value BeforeFilter 序列化时在最前添加内容*AfterFilter 序列化时在最后添加内容以上的SerializeFilter在JSON.toJSONString中可以使用。12SerializeFilter filter = ...; // 可以是上面5个SerializeFilter的任意一种。JSON.toJSONString(obj, filter); 通过ParseProcess定制反序列化 Fastjson 实例Fastjson 对象或数组转JSONFastjson阿里巴巴工程师开源的一个 json 库：Fastjson，这个库在解析速度和易用性上来说都很不错。在日志解析，前后端数据传输交互中，经常会遇到String与map、json、xml等格式相互转换与解析的场景，其中json基本成为了跨语言、跨前后端的事实上的标准数据交互格式。应该来说各个语言中解析json的库都一大片（具体 json 格式与三方库的介绍请见：http://www.json.org/json-zh.html ），比如python都集成在了内置库中，成为标准API，今天我们要聊的是java中如何方便的使用json格式。下面一个示例是如何使用Fastjson 把对象或数组转JSON1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.ohaotian.feifz.style.study.utils;/** * @author feifz * @version 1.0.0 * @Description alibaba fastjson工具类 * @createTime 2019年06月10日 11:45:00 */import com.alibaba.fastjson.JSON;import lombok.Data;import java.util.ArrayList;import java.util.List;class FastJsonTest &#123; public static void main(String[] args) &#123; // 构建用户geust User guestUser = new User(); guestUser.setName("guest"); guestUser.setAge(28); // 构建用户root User rootUser = new User(); rootUser.setName("root"); guestUser.setAge(35); // 构建用户组对象 UserGroup group = new UserGroup(); group.setName("admin"); group.getUsers().add(guestUser); group.getUsers().add(rootUser); // 用户组对象转JSON串 String jsonString = JSON.toJSONString(group); System.out.println("jsonString:" + jsonString); // JSON串转用户组对象 UserGroup group2 = JSON.parseObject(jsonString, UserGroup.class); System.out.println("group2:" + group2); // 构建用户对象数组 User[] users = new User[2]; users[0] = guestUser; users[1] = rootUser; // 用户对象数组转JSON串 String jsonString2 = JSON.toJSONString(users); System.out.println("jsonString2:" + jsonString2); // JSON串转用户对象列表 List&lt;User&gt; users2 = JSON.parseArray(jsonString2, User.class); System.out.println("users2:" + users2); &#125;&#125;@Dataclass User &#123; private String name; private int age;&#125;@Dataclass UserGroup &#123; private String name; private List&lt;User&gt; users = new ArrayList&lt;&gt;();&#125; 输出结果：1234jsonString:&#123;"name":"admin","users":[&#123;"age":35,"name":"guest"&#125;,&#123;"age":0,"name":"root"&#125;]&#125; group2:UserGroup [name=admin, users=[User [name=guest, age=35], User [name=root, age=0]]] jsonString2:[&#123;"age":35,"name":"guest"&#125;,&#123;"age":0,"name":"root"&#125;] users2:[User [name=guest, age=35], User [name=root, age=0]] fastjson通过各方面测试都很好，功能性能都是No.1，喜欢，它的源代码质量很高，作者也煞费苦心，将性能做到了最好，全面超越其他的json类库。通过fastjson我们可以快速进行开发。 Fastjson Obejct/Map/JSON/String 互转fastjson主要的使用入口Fastjson API入口类是com.alibaba.fastjson.JSON，常用的序列化操作都可以在JSON类上的静态方法直接完成。12345678public static final Object parse(String text); // 把JSON文本parse为JSONObject或者JSONArray public static final JSONObject parseObject(String text)； // 把JSON文本parse成JSONObject public static final &lt;T&gt; T parseObject(String text, Class&lt;T&gt; clazz); // 把JSON文本parse为JavaBean public static final JSONArray parseArray(String text); // 把JSON文本parse成JSONArray public static final &lt;T&gt; List&lt;T&gt; parseArray(String text, Class&lt;T&gt; clazz); //把JSON文本parse成JavaBean集合 public static final String toJSONString(Object object); // 将JavaBean序列化为JSON文本 public static final String toJSONString(Object object, boolean prettyFormat); // 将JavaBean序列化为带格式的JSON文本 public static final Object toJSON(Object javaObject); 将JavaBean转换为JSONObject或者JSONArray。 有关类库的一些说明1234SerializeWriter：相当于StringBufferJSONArray：相当于List&lt;Object&gt;JSONObject：相当于Map&lt;String, Object&gt;JSON反序列化没有真正数组，本质类型都是List&lt;Object&gt; 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134package com.ohaotian.feifz.style.study.utils;/** * @author feifz * @version 1.0.0 * @Description fastjson 高级应用 * @createTime 2019年06月10日 15:43:00 */import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONArray;import com.alibaba.fastjson.serializer.SerializeConfig;import com.alibaba.fastjson.serializer.SimpleDateFormatSerializer;import lombok.Data;import java.util.ArrayList;import java.util.Date;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.Random;/** * @author feifz * @version 1.0.0 * @Description alibaba fastjson高级应用 * @createTime 2019年06月10日 11:45:00 */public class FastjsonTest &#123; private static SerializeConfig mapping = new SerializeConfig(); static &#123; mapping.put(Date.class, new SimpleDateFormatSerializer("yyyy-MM-dd HH:mm:ss")); &#125; public static void main(String[] args) &#123; Date date = new Date(); String text = JSON.toJSONString(date, mapping); System.out.println(text); &#125; public static void json2List() &#123; /**List -&gt; JSON array*/ List&lt;Bar&gt; barList = new ArrayList&lt;Bar&gt;(); barList.add(new Bar()); barList.add(new Bar()); barList.add(new Bar()); String json = JSON.toJSONString(barList); System.out.println(json); json = JSON.toJSONString(barList, true); System.out.println(json); /**JSON array -&gt; List*/ List&lt;Bar&gt; barList1 = JSON.parseArray(json, Bar.class); for (Bar bar : barList1) &#123; System.out.println(bar.toString()); &#125; &#125; public static void json2Map() &#123; //Map -&gt; JSON Map&lt;String, Bar&gt; map = new HashMap&lt;String, Bar&gt;(); map.put("a", new Bar()); map.put("b", new Bar()); map.put("c", new Bar()); String json = JSON.toJSONString(map, true); System.out.println(json); //JSON -&gt; Map Map&lt;String, Bar&gt; map1 = (Map&lt;String, Bar&gt;) JSON.parse(json); for (String key : map1.keySet()) &#123; System.out.println(key + ":" + map1.get(key)); &#125; &#125; public static void array2JSON() &#123; String[] arr_String = &#123;"a", "b", "c"&#125;; String json_arr_String = JSON.toJSONString(arr_String, true); System.out.println(json_arr_String); JSONArray jsonArray = JSON.parseArray(json_arr_String); for (Object o : jsonArray) &#123; System.out.println(o); &#125; System.out.println(jsonArray); &#125; public static void array2JSON2() &#123; Bar[] arr_Bar = &#123;new Bar(), new Bar(), new Bar()&#125;; String json_arr_Bar = JSON.toJSONString(arr_Bar, true); System.out.println(json_arr_Bar); JSONArray jsonArray = JSON.parseArray(json_arr_Bar); for (Object o : jsonArray) &#123; System.out.println(o); &#125; System.out.println(jsonArray); &#125; public static void map2JSON() &#123; Map map = new HashMap(); map.put("a", "aaa"); map.put("b", "bbb"); map.put("c", "ccc"); String json = JSON.toJSONString(map); System.out.println(json); Map map1 = JSON.parseObject(json); for (Object o : map.entrySet()) &#123; Map.Entry&lt;String, String&gt; entry = (Map.Entry&lt;String, String&gt;) o; System.out.println(entry.getKey() + "---&gt;" + entry.getValue()); &#125; &#125;&#125;@Dataclass Bar &#123; public static SerializeConfig mapping = new SerializeConfig(); private String barName; private int barAge; private Date barDate = new Date(); static &#123; mapping.put(Date.class, new SimpleDateFormatSerializer("yyyy-MM-dd")); &#125; &#123; Random r = new Random(); barName = "sss_" + String.valueOf(r.nextFloat()); barAge = r.nextInt(); &#125; public static void main(String[] args) &#123; String x1 = JSON.toJSONString(new Bar(), true); System.out.println(x1); String x2 = JSON.toJSONString(new Bar(), mapping); System.out.println(x2); &#125;&#125; Fastjson API Fastjson JSONField Fastjson JSONPath Fastjson toJSONString Fastjson writeJSONString Fastjson parseObject Fastjson Api Compare Fastjson API Stream Fastjson API ParseProcess Fastjson API SerializeFilter Fastjson 常见问题参考 https://www.w3cschool.cn/fastjson https://www.jianshu.com/p/eaeaa5dce258]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>fastjson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http请求-okhttp3]]></title>
    <url>%2F2019%2F06%2F06%2FHttp%E8%AF%B7%E6%B1%82-okhttp3%2F</url>
    <content type="text"><![CDATA[简介 HTTP是现代应用常用的一种交换数据和媒体的网络方式，高效地使用HTTP能让资源加载更快，节省带宽。OkHttp是一个高效的HTTP客户端，它有以下默认特性： 支持HTTP/2，允许所有同一个主机地址的请求共享同一个socket连接 连接池减少请求延时 透明的GZIP压缩减少响应数据的大小 缓存响应内容，避免一些完全重复的请求 源码：https://github.com/square/okhttp说明：OkHttp支持Android 2.3及以上版本Android平台,对于Java, JDK1.7及以上。 当网络出现问题的时候OkHttp依然坚守自己的职责，它会自动恢复一般的连接问题，如果你的服务有多个IP地址，当第一个IP请求失败时，OkHttp会交替尝试你配置的其他IP，OkHttp使用现代TLS技术(SNI, ALPN)初始化新的连接，当握手失败时会回退到TLS 1.0。 简单使用引入maven依赖12345&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC1&lt;/version&gt;&lt;/dependency&gt; 请求方法同步请求 就是执行请求的操作是阻塞式，直到 HTTP 响应返回。它对应 OKHTTP 中的 execute 方法。 GET请求1234567891011121314151617181920/** * 同步get方式请求 * * @param url * @return * @throws IOException */public static String doGet(String url) throws IOException &#123; OkHttpClient client = new OkHttpClient(); Request request = new Request.Builder() .url(url) .build(); try (Response response = client.newCall(request).execute()) &#123; if (response.isSuccessful()) &#123; return response.body().string(); &#125; else &#123; throw new IOException("Unexpected code " + response); &#125; &#125;&#125; POST请求Json提交参数123456789101112131415161718192021222324/** * 同步post方式请求-json提交参数 * * @param url * @param json * @return * @throws IOException */ public static String doPost(String url, final String json) throws IOException &#123; OkHttpClient client = new OkHttpClient(); RequestBody body = RequestBody.create(JSON, json); Request request = new Request.Builder() .url(url) .post(body) .build(); try (Response response = client.newCall(request).execute()) &#123; if (response.isSuccessful()) &#123; return response.body().string(); &#125; else &#123; throw new IOException("Unexpected code " + response); &#125; &#125; &#125; form表单提交参数12345678910111213141516171819202122232425262728/** * 同步post方式请求-form表单提交参数 * * @param url * @param paramsMap * @return * @throws IOException */public static String doPost(String url, Map&lt;String, String&gt; paramsMap) throws IOException &#123; OkHttpClient client = new OkHttpClient(); FormBody.Builder builder = new FormBody.Builder(); for (String key : paramsMap.keySet()) &#123; builder.add(key, paramsMap.get(key)); &#125; RequestBody formBody = builder.build(); Request request = new Request.Builder() .url(url) .post(formBody) .build(); try (Response response = client.newCall(request).execute()) &#123; if (response.isSuccessful()) &#123; return response.body().string(); &#125; else &#123; throw new IOException("Unexpected code " + response); &#125; &#125;&#125; 异步请求 就是类似于非阻塞式的请求，它的执行结果一般都是通过接口回调的方式告知调用者。它对应 OKHTTP 中的 enqueue 方法。 这是异步请求，所以调用enqueue则无需再开启子线程，enqueue方法会自动将网络请求部分放入子线程中执行。enqueue回调方法onResponse与onFailure都执行在子线程中。注意事项： 回调接口的onFailure方法和onResponse执行在子线程。 Response.code是http响应行中的code，如果访问成功则返回200.这个不是服务器设置的，而是http协议中自带的。res中的code才是服务器设置的。注意二者的区别。 response.body().string()本质是输入流的读操作，所以它还是网络请求的一部分，所以这行代码必须放在子线程。 response.body().string()只能调用一次，在第一次时有返回值，第二次再调用时将会返回null。原因是：response.body().string()的本质是输入流的读操作，必须有服务器的输出流的写操作时客户端的读操作才能得到数据。而服务器的写操作只执行一次，所以客户端的读操作也只能执行一次，第二次将返回null。 再次强调，response.body().string()方法必须放在子线程中。当执行这行代码得到结果后，再跳转到UI线程修改UI。 异步请求自定义回调函数123456789101112131415161718/** * okhttp 异步调用回调函数 */ static class OkHttpCallback implements Callback &#123; @Override public void onFailure(@NotNull Call call, @NotNull IOException e) &#123; log.error(e); &#125; @Override public void onResponse(@NotNull Call call, @NotNull Response response) throws IOException &#123; if (response.isSuccessful()) &#123; log.info("Successful data acquisition . . . "); log.info("response.code()==" + response.code()); log.info("response.body().string()==" + response.body().string()); &#125; &#125; &#125; GET请求12345678910111213141516/** * 异步get方式请求 * * @param url * @return * @throws IOException */public static void doSyncGet(String url) &#123; OkHttpClient okHttpClient = new OkHttpClient(); final Request request = new Request.Builder() .url(url) .get() .build(); Call call = okHttpClient.newCall(request); call.enqueue(new OkHttpCallback());&#125; POST请求Json提交参数123456789101112131415161718/** * 异步post方式请求-json提交参数 * * @param url * @param json * @return * @throws IOException */public static void doSyncPost(String url, final String json) &#123; OkHttpClient client = new OkHttpClient(); RequestBody body = RequestBody.create(JSON, json); Request request = new Request.Builder() .url(url) .post(body) .build(); client.newCall(request).enqueue(new OkHttpCallback());&#125; form表单提交参数12345678910111213141516171819202122/** * 异步post方式请求-form表单提交参数 * * @param url * @param paramsMap * @return * @throws IOException */ public static void doSyncPost(String url, Map&lt;String, String&gt; paramsMap) &#123; OkHttpClient client = new OkHttpClient(); FormBody.Builder builder = new FormBody.Builder(); for (String key : paramsMap.keySet()) &#123; builder.add(key, paramsMap.get(key)); &#125; RequestBody formBody = builder.build(); Request request = new Request.Builder() .url(url) .post(formBody) .build(); client.newCall(request).enqueue(new OkHttpCallback()); &#125; 参考 https://www.jianshu.com/p/da4a806e599b https://blog.csdn.net/m0_38143863/article/details/80220247 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183package com.ohaotian.feifz.style.study.utils;import lombok.extern.log4j.Log4j2;import okhttp3.Call;import okhttp3.Callback;import okhttp3.FormBody;import okhttp3.MediaType;import okhttp3.OkHttpClient;import okhttp3.Request;import okhttp3.RequestBody;import okhttp3.Response;import org.jetbrains.annotations.NotNull;import java.io.IOException;import java.util.Map;/** * @author feifz * @version 1.0.0 * @Description http工具类，基于okhttp3 * @createTime 2019年06月06日 09:30:00 */@Log4j2public class HttpUtil &#123; public static final MediaType JSON = MediaType.get("application/json; charset=utf-8"); /** * 同步get方式请求 * * @param url * @return * @throws IOException */ public static String doGet(String url) throws IOException &#123; OkHttpClient client = new OkHttpClient(); Request request = new Request.Builder() .url(url) .build(); try (Response response = client.newCall(request).execute()) &#123; if (response.isSuccessful()) &#123; return response.body().string(); &#125; else &#123; throw new IOException("Unexpected code " + response); &#125; &#125; &#125; /** * 异步get方式请求 * * @param url * @return * @throws IOException */ public static void doSyncGet(String url) &#123; OkHttpClient okHttpClient = new OkHttpClient(); final Request request = new Request.Builder() .url(url) .get() .build(); Call call = okHttpClient.newCall(request); call.enqueue(new OkHttpCallback()); &#125; /** * 同步post方式请求-json提交参数 * * @param url * @param json * @return * @throws IOException */ public static String doPost(String url, final String json) throws IOException &#123; OkHttpClient client = new OkHttpClient(); RequestBody body = RequestBody.create(JSON, json); Request request = new Request.Builder() .url(url) .post(body) .build(); try (Response response = client.newCall(request).execute()) &#123; if (response.isSuccessful()) &#123; return response.body().string(); &#125; else &#123; throw new IOException("Unexpected code " + response); &#125; &#125; &#125; /** * 异步post方式请求-json提交参数 * * @param url * @param json * @return * @throws IOException */ public static void doSyncPost(String url, final String json) &#123; OkHttpClient client = new OkHttpClient(); RequestBody body = RequestBody.create(JSON, json); Request request = new Request.Builder() .url(url) .post(body) .build(); client.newCall(request).enqueue(new OkHttpCallback()); &#125; /** * 同步post方式请求-form表单提交参数 * * @param url * @param paramsMap * @return * @throws IOException */ public static String doPost(String url, Map&lt;String, String&gt; paramsMap) throws IOException &#123; OkHttpClient client = new OkHttpClient(); FormBody.Builder builder = new FormBody.Builder(); for (String key : paramsMap.keySet()) &#123; builder.add(key, paramsMap.get(key)); &#125; RequestBody formBody = builder.build(); Request request = new Request.Builder() .url(url) .post(formBody) .build(); try (Response response = client.newCall(request).execute()) &#123; if (response.isSuccessful()) &#123; return response.body().string(); &#125; else &#123; throw new IOException("Unexpected code " + response); &#125; &#125; &#125; /** * 异步post方式请求-form表单提交参数 * * @param url * @param paramsMap * @return * @throws IOException */ public static void doSyncPost(String url, Map&lt;String, String&gt; paramsMap) &#123; OkHttpClient client = new OkHttpClient(); FormBody.Builder builder = new FormBody.Builder(); for (String key : paramsMap.keySet()) &#123; builder.add(key, paramsMap.get(key)); &#125; RequestBody formBody = builder.build(); Request request = new Request.Builder() .url(url) .post(formBody) .build(); client.newCall(request).enqueue(new OkHttpCallback()); &#125; /** * okhttp 异步调用回调函数 */ static class OkHttpCallback implements Callback &#123; @Override public void onFailure(@NotNull Call call, @NotNull IOException e) &#123; log.error(e); &#125; @Override public void onResponse(@NotNull Call call, @NotNull Response response) throws IOException &#123; if (response.isSuccessful()) &#123; log.info("Successful data acquisition . . . "); log.info("response.code()==" + response.code()); log.info("response.body().string()==" + response.body().string()); &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>okhttp3</tag>
        <tag>开源项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka生产者发送消息的三种方式]]></title>
    <url>%2F2019%2F05%2F31%2FKafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[介绍Kafka是一种分布式的基于发布/订阅的消息系统，它的高吞吐量、灵活的offset是其它消息系统所没有的。 三种方式Kafka发送消息主要有三种方式： 发送并忘记 同步发送 异步发送+回调函数 发送并忘记发送并忘记(不关心消息是否正常到达，对返回结果不做任何判断处理)发送并忘记的方式本质上也是一种异步的方式，只是它不会获取消息发送的返回结果，这种方式的吞吐量是最高的，但是无法保证消息的可靠性. 123456789101112131415161718public static void wayOne() &#123; String brokeList = "127.0.0.1:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; producer.send(new ProducerRecord&lt;&gt;(topic, 0,key, String.valueOf(i))); &#125; producer.flush(); producer.close(); long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; 同步发送同步发送(通过get方法等待Kafka的响应，判断消息是否发送成功)以同步的方式发送消息时，一条一条的发送，对每条消息返回的结果判断， 可以明确地知道每条消息的发送情况，但是由于同步的方式会阻塞，只有当消息通过get返回future对象时，才会继续下一条消息的发送： 1234567891011121314151617181920212223public static void wayTwo() &#123; String brokeList = "39.96.117.232:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; Future&lt;RecordMetadata&gt; recordMetadataFuture = producer.send(new ProducerRecord&lt;&gt;(topic,key, String.valueOf(i))); try &#123; RecordMetadata record = recordMetadataFuture.get(10, TimeUnit.MICROSECONDS); System.out.println(record.toString()); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125; long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; 异步发送+回调函数异步发送+回调函数(消息以异步的方式发送，通过回调函数返回消息发送成功/失败)在调用send方法发送消息的同时，指定一个回调函数，服务器在返回响应时会调用该回调函数，通过回调函数能够对异常情况进行处理，当调用了回调函数时，只有回调函数执行完毕生产者才会结束，否则一直会阻塞。 123456789101112131415161718192021222324public static void wayThree() &#123; String brokeList = "39.96.117.232:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; producer.send(new ProducerRecord&lt;&gt;(topic, key, String.valueOf(i)), new Callback() &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; if(e==null)&#123; System.out.println("## 发送消息成功-&gt;"); &#125;else &#123; System.out.println("## 发送消息失败-&gt;&#123;&#125;"+e.getMessage()); &#125; &#125; &#125;); &#125; long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; 示例代码 基于java实现(待完善) 依赖jar包： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package com.ohaotian.feifz.mq.kafka;import org.apache.kafka.clients.producer.Callback;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.Producer;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;import java.util.Properties;import java.util.concurrent.Future;import java.util.concurrent.TimeUnit;/** * @Author: feifz * @Date: 2019-05-31 15:34 * @Version: 1.0 * @Description: kafka 发送消息三种方式发送消息示例代码 * @Refer https://www.cnblogs.com/FG123/p/10091478.html */public class KafkaSendMsgDemo &#123; public static void main(String[] args) &#123; /** 三种方式虽然在时间上有所差别，但并不是说时间越快的越好，具体要看业务的应用场景： 场景1：如果业务要求消息必须是按顺序发送的，那么可以使用同步的方式，并且只能在一个partation上或指定同一个key，结合参数设置retries的值让发送失败时重试，设置max_in_flight_requests_per_connection=1，可以控制生产者在收到服务器晌应之前只能发送1个消息，从而控制消息顺序发送； 场景2：如果业务只关心消息的吞吐量，容许少量消息发送失败，也不关注消息的发送顺序，那么可以使用发送并忘记的方式，并配合参数acks=0，这样生产者不需要等待服务器的响应，以网络能支持的最大速度发送消息； 场景3：如果业务需要知道消息发送是否成功，并且对消息的顺序不关心，那么可以用异步+回调的方式来发送消息，配合参数retries=0，并将发送失败的消息记录到日志文件中； * */ wayThree(); &#125; /** * 发送并忘记(不关心消息是否正常到达，对返回结果不做任何判断处理) */ public static void wayOne() &#123; String brokeList = "127.0.0.1:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; producer.send(new ProducerRecord&lt;&gt;(topic, 0,key, String.valueOf(i))); &#125; producer.flush(); producer.close(); long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; /** * 同步发送-(通过get方法等待Kafka的响应，判断消息是否发送成功) */ public static void wayTwo() &#123; String brokeList = "39.96.117.232:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; Future&lt;RecordMetadata&gt; recordMetadataFuture = producer.send(new ProducerRecord&lt;&gt;(topic,key, String.valueOf(i))); try &#123; RecordMetadata record = recordMetadataFuture.get(10, TimeUnit.MICROSECONDS); System.out.println(record.toString()); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125; long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; /** * 异步发送+回调函数(消息以异步的方式发送，通过回调函数返回消息发送成功/失败) */ public static void wayThree() &#123; String brokeList = "39.96.117.232:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; producer.send(new ProducerRecord&lt;&gt;(topic, key, String.valueOf(i)), new Callback() &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; if(e==null)&#123; System.out.println("## 发送消息成功-&gt;"); &#125;else &#123; System.out.println("## 发送消息失败-&gt;&#123;&#125;"+e.getMessage()); &#125; &#125; &#125;); &#125; long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; /** * 初始化producer * @param brokeList * @return */ private static Producer&lt;String, String&gt; initProducer(String brokeList) &#123; Properties props = new Properties(); props.put("bootstrap.servers", brokeList); props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("retries", 0); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); return producer; &#125;&#125;]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka安装与入门]]></title>
    <url>%2F2019%2F05%2F31%2FKafka%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[介绍Kafka 是一种高吞吐量的分布式发布订阅消息系统，有如下特性： 通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 高吞吐量 ：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。 支持通过Kafka服务器和消费机集群来分区消息。 支持Hadoop并行数据加载。 Kafka通过官网发布了最新版本2.0.0 安装 基于Linux和macos操作系统 参考 http://kafka.apache.org/quickstart http://orchome.com/6 Step 1: 下载代码 下载2.2.0版本并解压缩 12$ tar -xzf kafka_2.12-2.2.0.tgz$ cd kafka_2.12-2.2.0 Step 2: 启动服务 运行kafka需要使用Zookeeper，所以你需要先启动Zookeeper，如果你没有Zookeeper，你可以使用kafka自带打包和配置好的Zookeeper。1$ bin/zookeeper-server-start.sh config/zookeeper.properties 现在启动kafka服务1$ nohup bin/kafka-server-start.sh config/server.properties &amp; 入门 主要介绍发送Kafka消息，消费kafka消息等简单示例代码，以及使用过程中遇到的问题和解决方案 发送kafka消息示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.ohaotian.datatransmission.core.writer.kafka;import com.alibaba.fastjson.JSONObject;import lombok.extern.log4j.Log4j2;import org.apache.kafka.clients.producer.Callback;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.Producer;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;import java.util.Properties;/** * @Author: feifz * @Date: 2019-05-31 14:58 * @Version: 1.0 * @Description: kafka 发送消息示例 */@Log4j2public class KafkaProducerDemo &#123; public static void main(String[] args) &#123; String brokeList = "127.0.0.1:9092"; String topic = "testTopic"; String key = "testKey"; String message = "this is a test kafka message!"; Producer&lt;String, String&gt; producer = initProducer(brokeList); producer.send(new ProducerRecord&lt;&gt;(topic, key, JSONObject.toJSONString(message)), new Callback() &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; if (e == null) &#123; log.info("## 发送消息成功-&gt;&#123;&#125;", JSONObject.toJSONString(message)); &#125; else &#123; log.error("## 发送消息失败-&gt;&#123;&#125;", e.getMessage()); &#125; &#125; &#125;); producer.close(); &#125; /** * 初始化producer * @param brokeList * @return */ private static Producer&lt;String, String&gt; initProducer(String brokeList) &#123; Properties props = new Properties(); props.put("bootstrap.servers", brokeList); props.put("acks", "all"); props.put("retries", 0); props.put("batch.size", 16384); props.put("linger.ms", 1); props.put("buffer.memory", 33554432L); props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); return producer; &#125;&#125; 监控 参考：https://www.orchome.com/55 Kafka Manager简介为了简化开发者和服务工程师维护Kafka集群的工作，构建了一个叫做Kafka管理器的基于Web工具，叫做 Kafka Manager。这个管理工具可以很容易地发现分布在集群中的哪些topic分布不均匀，或者是分区在整个集群分布不均匀的的情况。它支持管理多个集群、选择副本、副本重新分配以及创建Topic。同时，这个管理工具也是一个非常好的可以快速浏览这个集群的工具。 该软件是用Scala语言编写的。目前(2015年02月03日)雅虎已经开源了Kafka Manager工具。这款Kafka集群管理工具主要支持以下几个功能： 管理几个不同的集群；很容易地检查集群的状态(topics, brokers, 副本的分布, 分区的分布)；选择副本；产生分区分配(Generate partition assignments)基于集群的当前状态；重新分配分区。 安装要求Kafka 0.8.. or 0.9.. or 0.10.. or 0.11..Java 8+sbt 0.13.x 配置系统至少需要配置zookeeper集群的地址，可以在kafka-manager安装包的conf目录下面的application.conf文件中进行配置。例如：1kafka-manager.zkhosts="my.zookeeper.host.com:2181" 你可以指定多个zookeeper地址，用逗号分隔：1kafka-manager.zkhosts="my.zookeeper.host.com:2181,other.zookeeper.host.com:2181" 另外, 如果你不想硬编码，可以使用环境变量ZK_HOSTS。1kafka-ZK_HOSTS="my.zookeeper.host.com:2181" 你可以启用/禁止以下的功能，通过修改application.config:1application.features=["KMClusterManagerFeature","KMTopicManagerFeature","KMPreferredReplicaElectionFeature","KMReassignPartitionsFeature"] KMClusterManagerFeature - 允许从Kafka Manager添加，更新，删除集群。KMTopicManagerFeature - 允许从Kafka集群中增加，更新，删除topicKMPreferredReplicaElectionFeature - 允许为Kafka集群运行首选副本KMReassignPartitionsFeature - 允许生成分区分配和重新分配分区考虑为启用了jmx的大群集设置这些参数： kafka-manager.broker-view-thread-pool-size=&lt; 3 * number_of_brokers&gt; kafka-manager.broker-view-max-queue-size=&lt; 3 * total # of partitions across all topics&gt; kafka-manager.broker-view-update-seconds=&lt; kafka-manager.broker-view-max-queue-size / (10 * number_of_brokers) &gt;下面是一个包含10个broker，100个topic的kafka集群示例，每个topic有10个分区，相当于1000个总分区，并启用JMX： kafka-manager.broker-view-thread-pool-size=30 kafka-manager.broker-view-max-queue-size=3000 kafka-manager.broker-view-update-seconds=30控制消费者偏offset缓存的线程池和队列： kafka-manager.offset-cache-thread-pool-size=&lt; default is # of processors&gt; kafka-manager.offset-cache-max-queue-size=&lt; default is 1000&gt; kafka-manager.kafka-admin-client-thread-pool-size=&lt; default is # of processors&gt; kafka-manager.kafka-admin-client-max-queue-size=&lt; default is 1000&gt;您应该在启用了消费者轮询的情况下为大量#消费者增加以上内容。虽然它主要影响基于ZK的消费者轮询。 Kafka管理的消费者offset现在由“__consumer_offsets”topic中的KafkaManagedOffsetCache消费。请注意，这尚未经过跟踪大量offset的测试。每个集群都有一个单独的线程消费这个topic，所以它可能无法跟上被推送到topic的大量offset。 部署下面的命令创建一个可部署应用的zip文件。1sbt clean dist 如果你不想拉源码，在编译，我已经编译好，放在百度云盘上了。 链接:https://pan.baidu.com/s/1AWQihB3CkF0g2Ao7lizTWw 密码:82eq 启动服务解压刚刚的zip文件,然后启动它:1$ bin/kafka-manager 默认情况下，端口为9000。可覆盖，例如：1$ bin/kafka-manager -Dconfig.file=/path/to/application.conf -Dhttp.port=8080 再如果java不在你的路径中，或你需要针对不同的版本，增加-java-home选项：1$ bin/kafka-manager -java-home /usr/local/oracle-java-8 用安全启动服务为SASL添加JAAS配置，添加配置文件位置：1$ bin/kafka-manager -Djava.security.auth.login.config=/path/to/my-jaas.conf 注意：确保运行kafka manager的用户有读取jaas配置文件的权限。 打包如果你想创建一个Debian或者RPM包，你可以使用下面命令打包：12sbt debian:packageBinsbt rpm:packageBin 常见问题1. 如何实现批量发送Kafka消息？生产者发送多个消息到同一个分区的时候，为了减少网络带来的系能开销，kafka会对消息进行批量发送。batch.size通过这个参数来设置批量提交的数据大小，默认是16k,当积压的消息达到这个值的时候就会统一发送（发往同一分区的消息）linger.ms这个设置是为发送设置一定是延迟来收集更多的消息，默认大小是0ms（就是有消息就立即发送）当这两个参数同时设置的时候，只要两个条件中满足一个就会发送。比如说batch.size设置16kb，linger.ms设置50ms，那么当消息积压达到16kb就会发送，如果没有到达16kb，那么在第一个消息到来之后的50ms之后消息将会发送。 2. Kafka如何保证消息的可靠性传输？这块比较常见的一个场景，就是Kafka某个broker宕机，然后重新选举partition 的leader。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader 挂了，然后选举某个follower成leader之后，不就少了一些数据？这就丢了一些数据啊。生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将follower切换为 leader 之后，就会发现说这个数据就丢了。所以此时一般是要求起码设置如下 4 个参数：给topic设置replication.factor参数：这个值必须大于1，要求每个 partition必须有至少2个副本。在Kafka服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧。在producer端设置 acks=all：这个是要求每条数据，必须是写入所有replica 之后，才能认为是写成功了。在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。我们生产环境就是按照上述要求配置的，这样配置之后，至少在Kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失。生产者会不会弄丢数据？如果按照上述的思路设置了acks=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch安装与入门]]></title>
    <url>%2F2019%2F05%2F31%2FElasticSearch%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[介绍 ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 安装ElasticSearch安装 进入官网下载页选择想要安装的版本下载：https://www.elastic.co/downloads/past-releases 解压缩至本地某地址 cd bin 执行命令:./elasticsearch 启动成功 ElasticSearch-head插件安装 （参考：https://blog.csdn.net/mingleizhen/article/details/76084874） 依赖环境：node和npm git clone https://github.com/mobz/elasticsearch-head.git npm install npm run start 修改ElasticSearch配置 在elasticsearch.yml添加如下配置 http.cors.enabled: true http.cors.allow-origin: “* 重启ES 页面访问：http://localhost:9100/ 启动完成 验证 访问：http://localhost:9100/]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>Elastic S e a r ch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发-线程池的使用]]></title>
    <url>%2F2019%2F05%2F29%2FJava%E5%B9%B6%E5%8F%91-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[说明 参考：https://www.cnblogs.com/dolphin0520/p/3932921.html 如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，因为频繁创建线程和销毁线程需要时间，这样频繁创建线程就会大大降低系统的效率。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？ 在Java中可以通过线程池来达到这样的效果。今天我们就来详细讲解一下Java的线程池，首先我们从最核心的ThreadPoolExecutor类中的方法讲起，然后再讲述它的实现原理，接着给出了它的使用示例，最后讨论了一下如何合理配置线程池的大小。 Java中的ThreadPoolExecutor类 java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// Public constructors and methods public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 下面解释下一下构造器中各个参数的含义： corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： 1234567TimeUnit.DAYS; //天TimeUnit.HOURS; //小时TimeUnit.MINUTES; //分钟TimeUnit.SECONDS; //秒TimeUnit.MILLISECONDS; //毫秒TimeUnit.MICROSECONDS; //微妙TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。 1234ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue;PriorityBlockingQueue threadFactory：线程工厂，主要用来创建线程； handler：表示当拒绝处理任务时的策略，有以下四种取值： 1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 具体参数的配置与线程池的关系将在下一节讲述。 从上面给出的ThreadPoolExecutor类的代码可以知道，ThreadPoolExecutor继承了AbstractExecutorService，我们来看一下AbstractExecutorService的实现： 123456789101112131415161718192021222324252627public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; &#125;; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; &#125;; public Future&lt;?&gt; submit(Runnable task) &#123;&#125;; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; &#125;; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; &#125;; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;;&#125; AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。 我们接着看ExecutorService接口的实现： 12345678910111213141516171819202122public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 而ExecutorService又是继承了Executor接口，我们看一下Executor接口的实现： 123public interface Executor &#123; void execute(Runnable command);&#125; 到这里，大家应该明白了ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor几个之间的关系了。 Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的； 然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等； 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法； 然后ThreadPoolExecutor继承了类AbstractExecutorService。 在ThreadPoolExecutor类中有几个非常重要的方法： 1234execute()submit()shutdown()shutdownNow() execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果（Future相关内容将在下一篇讲述）。 shutdown()和shutdownNow()是用来关闭线程池的。 还有很多其他的方法： 比如：getQueue() 、getPoolSize() 、getActiveCount()、getCompletedTaskCount()等获取与线程池相关属性的方法，有兴趣的朋友可以自行查阅API。 深入剖析线程池实现原理在上一节我们从宏观上介绍了ThreadPoolExecutor，下面我们来深入解析一下线程池的具体实现原理，将从下面几个方面讲解： 1.线程池状态 2.任务的执行 3.线程池中的线程初始化 4.任务缓存队列及排队策略 5.任务拒绝策略 6.线程池的关闭 7.线程池容量的动态调整 1.线程池状态 在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态： 12345volatile int runState;static final int RUNNING = 0;static final int SHUTDOWN = 1;static final int STOP = 2;static final int TERMINATED = 3; runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性； 下面的几个static final变量表示runState可能的几个取值。 当创建线程池后，初始时，线程池处于RUNNING状态； 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 2.任务的执行 在了解将任务提交给线程池到任务执行完毕整个过程之前，我们先来看一下ThreadPoolExecutor类中其他的一些比较重要成员变量： 12345678910111213141516171819private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小 //、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集 private volatile long keepAliveTime; //线程存货时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数 private volatile int poolSize; //线程池中当前的线程数 private volatile RejectedExecutionHandler handler; //任务拒绝策略 private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程 private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; //用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子： 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。 因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 下面我们进入正题，看一下任务从提交到最终执行完毕经历了哪些过程。 在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可： 123456789101112public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123; if (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123; if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); &#125; else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated &#125;&#125; 上面的代码可能看起来不是那么容易理解，下面我们一句一句解释： 首先，判断提交的任务command是否为null，若是null，则抛出空指针异常； 接着是这句，这句要好好理解一下： 1`if` `(poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command))` 由于是或条件运算符，所以先计算前半部分的值，如果线程池中当前线程数不小于核心池大小，那么就会直接进入下面的if语句块了。 如果线程池中当前线程数小于核心池大小，则接着执行后半部分，也就是执行 1`addIfUnderCorePoolSize(command)` 如果执行完addIfUnderCorePoolSize这个方法返回false，则继续执行下面的if语句块，否则整个方法就直接执行完毕了。 如果执行完addIfUnderCorePoolSize这个方法返回true，然后接着判断： 1`if` `(runState == RUNNING &amp;&amp; workQueue.offer(command))` 如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行： 1`addIfUnderMaximumPoolSize(command)` 如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。 回到前面： 1`if` `(runState == RUNNING &amp;&amp; workQueue.offer(command))` 这句的执行，如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续进行判断： 1`if` `(runState != RUNNING || poolSize == ``0``)` 这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施。如果是这样就执行： 1`ensureQueuedTaskHandled(command)` 进行应急处理，从名字可以看出是保证 添加到任务缓存队列中的任务得到处理。 我们接着看2个关键方法的实现：addIfUnderCorePoolSize和addIfUnderMaximumPoolSize： 1`private` `boolean` `addIfUnderCorePoolSize(Runnable firstTask) &#123;`` ``Thread t = ``null``;`` ``final` `ReentrantLock mainLock = ``this``.mainLock;`` ``mainLock.lock();`` ``try` `&#123;`` ``if` `(poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING)`` ``t = addThread(firstTask); ``//创建线程去执行firstTask任务 `` ``&#125; ``finally` `&#123;`` ``mainLock.unlock();`` ``&#125;`` ``if` `(t == ``null``)`` ``return` `false``;`` ``t.start();`` ``return` `true``;``&#125;` 这个是addIfUnderCorePoolSize方法的具体实现，从名字可以看出它的意图就是当低于核心池大小时执行的方法。下面看其具体实现，首先获取到锁，因为这地方涉及到线程池状态的变化，先通过if语句判断当前线程池中的线程数目是否小于核心池大小，有朋友也许会有疑问：前面在execute()方法中不是已经判断过了吗，只有线程池当前线程数目小于核心池大小才会执行addIfUnderCorePoolSize方法的，为何这地方还要继续判断？原因很简单，前面的判断过程中并没有加锁，因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了，所以需要在这个地方继续判断。然后接着判断线程池的状态是否为RUNNING，原因也很简单，因为有可能在其他线程中调用了shutdown或者shutdownNow方法。然后就是执行 1`t = addThread(firstTask);` 这个方法也非常关键，传进去的参数为提交的任务，返回值为Thread类型。然后接着在下面判断t是否为空，为空则表明创建线程失败（即poolSize&gt;=corePoolSize或者runState不等于RUNNING），否则调用t.start()方法启动线程。 我们来看一下addThread方法的实现： 1`private` `Thread addThread(Runnable firstTask) &#123;`` ``Worker w = ``new` `Worker(firstTask);`` ``Thread t = threadFactory.newThread(w); ``//创建一个线程，执行任务 `` ``if` `(t != ``null``) &#123;`` ``w.thread = t; ``//将创建的线程的引用赋值为w的成员变量 `` ``workers.add(w);`` ``int` `nt = ++poolSize; ``//当前线程数加1 `` ``if` `(nt &gt; largestPoolSize)`` ``largestPoolSize = nt;`` ``&#125;`` ``return` `t;``&#125;` 在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。 下面我们看一下Worker类的实现： 1`private` `final` `class` `Worker ``implements` `Runnable &#123;`` ``private` `final` `ReentrantLock runLock = ``new` `ReentrantLock();`` ``private` `Runnable firstTask;`` ``volatile` `long` `completedTasks;`` ``Thread thread;`` ``Worker(Runnable firstTask) &#123;`` ``this``.firstTask = firstTask;`` ``&#125;`` ``boolean` `isActive() &#123;`` ``return` `runLock.isLocked();`` ``&#125;`` ``void` `interruptIfIdle() &#123;`` ``final` `ReentrantLock runLock = ``this``.runLock;`` ``if` `(runLock.tryLock()) &#123;`` ``try` `&#123;`` ``if` `(thread != Thread.currentThread())`` ``thread.interrupt();`` ``&#125; ``finally` `&#123;`` ``runLock.unlock();`` ``&#125;`` ``&#125;`` ``&#125;`` ``void` `interruptNow() &#123;`` ``thread.interrupt();`` ``&#125;` ` ``private` `void` `runTask(Runnable task) &#123;`` ``final` `ReentrantLock runLock = ``this``.runLock;`` ``runLock.lock();`` ``try` `&#123;`` ``if` `(runState &lt; STOP &amp;&amp;`` ``Thread.interrupted() &amp;&amp;`` ``runState &gt;= STOP)`` ``boolean` `ran = ``false``;`` ``beforeExecute(thread, task); ``//beforeExecute方法是ThreadPoolExecutor类的一个方法，没有具体实现，用户可以根据`` ``//自己需要重载这个方法和后面的afterExecute方法来进行一些统计信息，比如某个任务的执行时间等 `` ``try` `&#123;`` ``task.run();`` ``ran = ``true``;`` ``afterExecute(task, ``null``);`` ``++completedTasks;`` ``&#125; ``catch` `(RuntimeException ex) &#123;`` ``if` `(!ran)`` ``afterExecute(task, ex);`` ``throw` `ex;`` ``&#125;`` ``&#125; ``finally` `&#123;`` ``runLock.unlock();`` ``&#125;`` ``&#125;` ` ``public` `void` `run() &#123;`` ``try` `&#123;`` ``Runnable task = firstTask;`` ``firstTask = ``null``;`` ``while` `(task != ``null` `|| (task = getTask()) != ``null``) &#123;`` ``runTask(task);`` ``task = ``null``;`` ``&#125;`` ``&#125; ``finally` `&#123;`` ``workerDone(``this``); ``//当任务队列中没有任务时，进行清理工作 `` ``&#125;`` ``&#125;``&#125;` 它实际上实现了Runnable接口，因此上面的Thread t = threadFactory.newThread(w);效果跟下面这句的效果基本一样： 1`Thread t = ``new` `Thread(w);` 相当于传进去了一个Runnable任务，在线程t中执行这个Runnable。 既然Worker实现了Runnable接口，那么自然最核心的方法便是run()方法了： 1`public` `void` `run() &#123;`` ``try` `&#123;`` ``Runnable task = firstTask;`` ``firstTask = ``null``;`` ``while` `(task != ``null` `|| (task = getTask()) != ``null``) &#123;`` ``runTask(task);`` ``task = ``null``;`` ``&#125;`` ``&#125; ``finally` `&#123;`` ``workerDone(``this``);`` ``&#125;``&#125;` 从run方法的实现可以看出，它首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，那么去哪里取呢？自然是从任务缓存队列里面去取，getTask是ThreadPoolExecutor类中的方法，并不是Worker类中的方法，下面是getTask方法的实现： 1`Runnable getTask() &#123;`` ``for` `(;;) &#123;`` ``try` `&#123;`` ``int` `state = runState;`` ``if` `(state &gt; SHUTDOWN)`` ``return` `null``;`` ``Runnable r;`` ``if` `(state == SHUTDOWN) ``// Help drain queue`` ``r = workQueue.poll();`` ``else` `if` `(poolSize &gt; corePoolSize || allowCoreThreadTimeOut) ``//如果线程数大于核心池大小或者允许为核心池线程设置空闲时间，`` ``//则通过poll取任务，若等待一定的时间取不到任务，则返回null`` ``r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS);`` ``else`` ``r = workQueue.take();`` ``if` `(r != ``null``)`` ``return` `r;`` ``if` `(workerCanExit()) &#123; ``//如果没取到任务，即r为null，则判断当前的worker是否可以退出`` ``if` `(runState &gt;= SHUTDOWN) ``// Wake up others`` ``interruptIdleWorkers(); ``//中断处于空闲状态的worker`` ``return` `null``;`` ``&#125;`` ``// Else retry`` ``&#125; ``catch` `(InterruptedException ie) &#123;`` ``// On interruption, re-check runState`` ``&#125;`` ``&#125;``&#125;` 在getTask中，先判断当前线程池状态，如果runState大于SHUTDOWN（即为STOP或者TERMINATED），则直接返回null。 如果runState为SHUTDOWN或者RUNNING，则从任务缓存队列取任务。 如果当前线程池的线程数大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，则调用poll(time,timeUnit)来取任务，这个方法会等待一定的时间，如果取不到任务就返回null。 然后判断取到的任务r是否为null，为null则通过调用workerCanExit()方法来判断当前worker是否可以退出，我们看一下workerCanExit()的实现： 1`private` `boolean` `workerCanExit() &#123;`` ``final` `ReentrantLock mainLock = ``this``.mainLock;`` ``mainLock.lock();`` ``boolean` `canExit;`` ``//如果runState大于等于STOP，或者任务缓存队列为空了`` ``//或者 允许为核心池线程设置空闲存活时间并且线程池中的线程数目大于1`` ``try` `&#123;`` ``canExit = runState &gt;= STOP ||`` ``workQueue.isEmpty() ||`` ``(allowCoreThreadTimeOut &amp;&amp;`` ``poolSize &gt; Math.max(``1``, corePoolSize));`` ``&#125; ``finally` `&#123;`` ``mainLock.unlock();`` ``&#125;`` ``return` `canExit;``&#125;` 也就是说如果线程池处于STOP状态、或者任务队列已为空或者允许为核心池线程设置空闲存活时间并且线程数大于1时，允许worker退出。如果允许worker退出，则调用interruptIdleWorkers()中断处于空闲状态的worker，我们看一下interruptIdleWorkers()的实现： 1`void` `interruptIdleWorkers() &#123;`` ``final` `ReentrantLock mainLock = ``this``.mainLock;`` ``mainLock.lock();`` ``try` `&#123;`` ``for` `(Worker w : workers) ``//实际上调用的是worker的interruptIfIdle()方法`` ``w.interruptIfIdle();`` ``&#125; ``finally` `&#123;`` ``mainLock.unlock();`` ``&#125;``&#125;` 从实现可以看出，它实际上调用的是worker的interruptIfIdle()方法，在worker的interruptIfIdle()方法中： 1`void` `interruptIfIdle() &#123;`` ``final` `ReentrantLock runLock = ``this``.runLock;`` ``if` `(runLock.tryLock()) &#123; ``//注意这里，是调用tryLock()来获取锁的，因为如果当前worker正在执行任务，锁已经被获取了，是无法获取到锁的`` ``//如果成功获取了锁，说明当前worker处于空闲状态`` ``try` `&#123;`` ``if` `(thread != Thread.currentThread()) `` ``thread.interrupt();`` ``&#125; ``finally` `&#123;`` ``runLock.unlock();`` ``&#125;`` ``&#125;``&#125;` 这里有一个非常巧妙的设计方式，假如我们来设计线程池，可能会有一个任务分派线程，当发现有线程空闲时，就从任务缓存队列中取一个任务交给空闲线程执行。但是在这里，并没有采用这样的方式，因为这样会要额外地对任务分派线程进行管理，无形地会增加难度和复杂度，这里直接让执行完任务的线程去任务缓存队列里面取任务来执行。 我们再看addIfUnderMaximumPoolSize方法的实现，这个方法的实现思想和addIfUnderCorePoolSize方法的实现思想非常相似，唯一的区别在于addIfUnderMaximumPoolSize方法是在线程池中的线程数达到了核心池大小并且往任务队列中添加任务失败的情况下执行的： 1`private` `boolean` `addIfUnderMaximumPoolSize(Runnable firstTask) &#123;`` ``Thread t = ``null``;`` ``final` `ReentrantLock mainLock = ``this``.mainLock;`` ``mainLock.lock();`` ``try` `&#123;`` ``if` `(poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING)`` ``t = addThread(firstTask);`` ``&#125; ``finally` `&#123;`` ``mainLock.unlock();`` ``&#125;`` ``if` `(t == ``null``)`` ``return` `false``;`` ``t.start();`` ``return` `true``;``&#125;` 看到没有，其实它和addIfUnderCorePoolSize方法的实现基本一模一样，只是if语句判断条件中的poolSize &lt; maximumPoolSize不同而已。 到这里，大部分朋友应该对任务提交给线程池之后到被执行的整个过程有了一个基本的了解，下面总结一下： 1）首先，要清楚corePoolSize和maximumPoolSize的含义； 2）其次，要知道Worker是用来起到什么作用的； 3）要知道任务提交给线程池之后的处理策略，这里总结一下主要有4点： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 3.线程池中的线程初始化 默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 下面是这2个方法的实现： 1`public` `boolean` `prestartCoreThread() &#123;`` ``return` `addIfUnderCorePoolSize(``null``); ``//注意传进去的参数是null``&#125;` `public` `int` `prestartAllCoreThreads() &#123;`` ``int` `n = ``0``;`` ``while` `(addIfUnderCorePoolSize(``null``))``//注意传进去的参数是null`` ``++n;`` ``return` `n;``&#125;` 注意上面传进去的参数是null，根据第2小节的分析可知如果传进去的参数为null，则最后执行线程会阻塞在getTask方法中的 1`r = workQueue.take();` 即等待任务队列中有任务。 4.任务缓存队列及排队策略 在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。 workQueue的类型为BlockingQueue，通常可以取下面三种类型： 1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； 2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； 3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 5.任务拒绝策略 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： 1`ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。``ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。``ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）``ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务` 6.线程池的关闭 ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 7.线程池容量的动态调整 ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 使用示例前面我们讨论了关于线程池的实现原理，这一节我们来看一下它的具体使用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.ohaotian.feifz.style.study.thread;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author feifz * @version 1.0.0 * @Description 线程池示例 * @createTime 2019年05月28日 16:31:00 */public class ThreadDemoTest &#123; public static void main(String[] args) &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5)); for (int i = 0; i &lt; 15; i++) &#123; MyTask myTask = new MyTask(i); executor.execute(myTask); System.out.println("线程池中线程数目：" + executor.getPoolSize() + "，队列中等待执行的任务数目：" + executor.getQueue().size() + "，已执行玩别的任务数目：" + executor.getCompletedTaskCount()); &#125; executor.shutdown(); &#125;&#125;class MyTask implements Runnable &#123; private int taskNum; public MyTask(int num) &#123; this.taskNum = num; &#125; @Override public void run() &#123; System.out.println("正在执行task " + taskNum); try &#123; Thread.currentThread().sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("task " + taskNum + "执行完毕"); &#125;&#125; 从执行结果可以看出，当线程池中线程的数目大于5时，便将任务放入任务缓存队列里面，当任务缓存队列满了之后，便创建新的线程。如果上面程序中，将for循环中改成执行20个任务，就会抛出任务拒绝异常了。 不过在java doc中，并不提倡我们直接使用ThreadPoolExecutor，而是使用Executors类中提供的几个静态方法来创建线程池： 123Executors.newCachedThreadPool(); //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUEExecutors.newSingleThreadExecutor(); //创建容量为1的缓冲池Executors.newFixedThreadPool(int); //创建固定容量大小的缓冲池 下面是这三个静态方法的具体实现; 12345678910111213141516public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 从它们的具体实现来看，它们实际上也是调用了ThreadPoolExecutor，只不过参数都已配置好了。 newFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue； newSingleThreadExecutor将corePoolSize和maximumPoolSize都设置为1，也使用的LinkedBlockingQueue； newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 实际中，如果Executors提供的三个静态方法能满足要求，就尽量使用它提供的三个方法，因为自己去手动配置ThreadPoolExecutor的参数有点麻烦，要根据实际任务的类型和数量来进行配置。 另外，如果ThreadPoolExecutor达不到要求，可以自己继承ThreadPoolExecutor类进行重写。 如何合理配置线程池的大小本节来讨论一个比较重要的话题：如何合理配置线程池大小，仅供参考。 一般需要根据任务的类型来配置线程池大小： 如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1 如果是IO密集型任务，参考值可以设置为2*NCPU 当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。]]></content>
      <tags>
        <tag>Java并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown入门指南]]></title>
    <url>%2F2019%2F05%2F12%2FUntitled%2F</url>
    <content type="text"><![CDATA[参考：https://www.jianshu.com/p/q81RER 标题而在 Markdown 中，你只需要在文本前面加上 # 即可，同理、你还可以增加二级标题、三级标题、四级标题、五级标题和六级标题，总共六级，只需要增加 # 即可，标题字号相应降低。例如：123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 注：# 和「一级标题」之间建议保留一个字符的空格，这是最标准的 Markdown 写法。 列表列表格式也很常用，在 Markdown 中，你只需要在文字前面加上 - 就可以了，例如： 代码： 123- 文本1- 文本2- 文本3 效果： 文本1 文本2 文本3 如果你希望有序列表，也可以在文字前面加上 1. 2. 3. 就可以了，例如：代码： 1231. 文本12. 文本23. 文本3 效果： 文本1 文本2 文本3 注：-、1.和文本之间要保留一个字符的空格。 插入链接和图片在 Markdown 中，插入链接不需要其他按钮，你只需要使用 显示文本 这样的语法即可，例如：代码： 1[简书](http://www.jianshu.com) 效果： 简书 在 Markdown 中，插入图片不需要其他按钮，你只需要使用 这样的语法即可，例如：代码： 1![](http://upload-images.jianshu.io/upload_images/259-0ad0d0bfc1c608b6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 效果： 注：插入图片的语法和链接的语法很像，只是前面多了一个 ！。 引用在我们写作的时候经常需要引用他人的文字，这个时候引用这个格式就很有必要了，在 Markdown 中，你只需要在你希望引用的文字前面加上 &gt; 就好了，例如： 代码： 1&gt; 一盏灯， 一片昏黄； 一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。 效果： 一盏灯， 一片昏黄； 一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。 注：&gt; 和文本之间要保留一个字符的空格。 粗体和斜体Markdown 的粗体和斜体也非常简单，用两个 包含一段文本就是粗体的语法，用一个 包含一段文本就是斜体的语法。例如： 代码： 1*一盏灯*， 一片昏黄；**一简书**， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。 效果： 一盏灯， 一片昏黄；一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。 最终显示的就是下文，其中「一盏灯」是斜体，「一简书」是粗体： 代码引用12需要引用代码时，如果引用的语句只有一段，不分行，可以用 ` 将语句包起来。如果引用的语句为多行，可以将```置于这段代码的首行和末行。 表格相关代码： 12345| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 显示效果：| Tables | Are | Cool || ————- |:————-:| —–:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 显示链接中带括号的图片代码如下:12![][1][1]: http://latex.codecogs.com/gif.latex?\prod%20\(n_&#123;i&#125;\)+1 效果如下：![][1][1]: http://latex.codecogs.com/gif.latex?\prod%20\(n_{i}\)+1]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>makedown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo入门到进阶]]></title>
    <url>%2F2019%2F05%2F12%2FHexo%20%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 官方文档(这里主要记录本人在使用Hexo过程中遇到的问题和解决方案) 基本使用init1$ hexo init [folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new1$ hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 1$ hexo new "post title with whitespace" generate1$ hexo generate 生成静态文件。 选项 描述 -d, --deploy 文件生成后立即部署网站 -w, --watch 监视文件变动 该命令可以简写为1$ hexo g publish1$ hexo publish [layout] &lt;filename&gt; 发表草稿。 server1$ hexo server 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 选项 描述 -p, --port 重设端口 -s, --static 只使用静态文件 -l, --log 启动日记记录，使用覆盖记录格式 该命令可以简写为1234567$ hexo s`## deploy``` bash$ hexo deploy 部署网站。 参数 描述 -g, --generate 部署之前预先生成静态文件 该命令可以简写为：1$ hexo d render1$ hexo render &lt;file1&gt; [file2] ... 渲染文件。 参数 描述 -o, --output 设置输出路径 migrate1$ hexo migrate &lt;type&gt; 从其他博客系统 迁移内容。 clean1$ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 list1$ hexo list &lt;type&gt; 列出网站资料。 version1$ hexo version 插件Hexo-admin插件介绍hexo-admin 是一个Hexo博客引擎的管理用户界面插件。这个插件最初是作为本地编辑器设计的，在本地运行hexo使用hexo-admin编写文章，然后通过hexo g或hexo d（hexo g是本地渲染，hexo d是将渲染的静态页面发布到GitHub）将生成的静态页面发布到GitHub等静态服务器。如果你使用的是非静态托管服务器，比如自己买的主机搭建的hexo，那么一定要设置hexo-admin 的密码，否则谁都可以编辑你的文章。 插件安装首先进入hexo创建的博客项目的根目录下，执行1234567 npm install --save hexo-admin``` mac可能需要root权限，前面加个sudo 就可以了。如果报错缺少组件，则缺少什么安装什么，npm install 加缺少的组件。运行下列命令启动hexo-admin ：``` bash hexo server -d 打开 http://localhost:4000/admin/ 就可以访问到hexo-admin管理页面了。 密码保护打开setting，点击Setup authentification here输入用户名，密码，密钥，下面会自动生成配置文件，复制加在hexo根目录下的_config.yml中：1234admin: username: username password_hash: be121740bf988b2225a313fa1f107ca1 secret: secret 重启hexo，就可以看到登录页面了 发布文章进入后台之后点击Deploy，里面的Deploy按钮是用来执行发布脚本的，所以我们先在博客根目录下新建个目录admin_script，然后在目录中新建一个脚本hexo-g.sh，里面写下下面代码然后保存， hexo g &amp;&amp; hexo d 然后在_config.yml中的admin下添加 admin: username: username password_hash: be121740bf988b2225a313fa1f107ca1 secret: secret deployCommand: ./admin_script/hexo-g.sh 设置发布执行的脚本，点击Deploy就会执行这个命令并提交到GitHub上。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
