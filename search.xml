<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kafka生产者发送消息的三种方式]]></title>
    <url>%2F2019%2F05%2F31%2FKafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[介绍Kafka是一种分布式的基于发布/订阅的消息系统，它的高吞吐量、灵活的offset是其它消息系统所没有的。 三种方式Kafka发送消息主要有三种方式： 发送并忘记 同步发送 异步发送+回调函数 发送并忘记发送并忘记(不关心消息是否正常到达，对返回结果不做任何判断处理)发送并忘记的方式本质上也是一种异步的方式，只是它不会获取消息发送的返回结果，这种方式的吞吐量是最高的，但是无法保证消息的可靠性. 123456789101112131415161718public static void wayOne() &#123; String brokeList = "127.0.0.1:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; producer.send(new ProducerRecord&lt;&gt;(topic, 0,key, String.valueOf(i))); &#125; producer.flush(); producer.close(); long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; 同步发送同步发送(通过get方法等待Kafka的响应，判断消息是否发送成功)以同步的方式发送消息时，一条一条的发送，对每条消息返回的结果判断， 可以明确地知道每条消息的发送情况，但是由于同步的方式会阻塞，只有当消息通过get返回future对象时，才会继续下一条消息的发送： 1234567891011121314151617181920212223public static void wayTwo() &#123; String brokeList = "39.96.117.232:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; Future&lt;RecordMetadata&gt; recordMetadataFuture = producer.send(new ProducerRecord&lt;&gt;(topic,key, String.valueOf(i))); try &#123; RecordMetadata record = recordMetadataFuture.get(10, TimeUnit.MICROSECONDS); System.out.println(record.toString()); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125; long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; 异步发送+回调函数异步发送+回调函数(消息以异步的方式发送，通过回调函数返回消息发送成功/失败)在调用send方法发送消息的同时，指定一个回调函数，服务器在返回响应时会调用该回调函数，通过回调函数能够对异常情况进行处理，当调用了回调函数时，只有回调函数执行完毕生产者才会结束，否则一直会阻塞。 123456789101112131415161718192021222324public static void wayThree() &#123; String brokeList = "39.96.117.232:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; producer.send(new ProducerRecord&lt;&gt;(topic, key, String.valueOf(i)), new Callback() &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; if(e==null)&#123; System.out.println("## 发送消息成功-&gt;"); &#125;else &#123; System.out.println("## 发送消息失败-&gt;&#123;&#125;"+e.getMessage()); &#125; &#125; &#125;); &#125; long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; 示例代码 基于java实现(待完善) 依赖jar包： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package com.ohaotian.feifz.mq.kafka;import org.apache.kafka.clients.producer.Callback;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.Producer;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;import java.util.Properties;import java.util.concurrent.Future;import java.util.concurrent.TimeUnit;/** * @Author: feifz * @Date: 2019-05-31 15:34 * @Version: 1.0 * @Description: kafka 发送消息三种方式发送消息示例代码 * @Refer https://www.cnblogs.com/FG123/p/10091478.html */public class KafkaSendMsgDemo &#123; public static void main(String[] args) &#123; /** 三种方式虽然在时间上有所差别，但并不是说时间越快的越好，具体要看业务的应用场景： 场景1：如果业务要求消息必须是按顺序发送的，那么可以使用同步的方式，并且只能在一个partation上或指定同一个key，结合参数设置retries的值让发送失败时重试，设置max_in_flight_requests_per_connection=1，可以控制生产者在收到服务器晌应之前只能发送1个消息，从而控制消息顺序发送； 场景2：如果业务只关心消息的吞吐量，容许少量消息发送失败，也不关注消息的发送顺序，那么可以使用发送并忘记的方式，并配合参数acks=0，这样生产者不需要等待服务器的响应，以网络能支持的最大速度发送消息； 场景3：如果业务需要知道消息发送是否成功，并且对消息的顺序不关心，那么可以用异步+回调的方式来发送消息，配合参数retries=0，并将发送失败的消息记录到日志文件中； * */ wayThree(); &#125; /** * 发送并忘记(不关心消息是否正常到达，对返回结果不做任何判断处理) */ public static void wayOne() &#123; String brokeList = "127.0.0.1:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; producer.send(new ProducerRecord&lt;&gt;(topic, 0,key, String.valueOf(i))); &#125; producer.flush(); producer.close(); long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; /** * 同步发送-(通过get方法等待Kafka的响应，判断消息是否发送成功) */ public static void wayTwo() &#123; String brokeList = "39.96.117.232:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; Future&lt;RecordMetadata&gt; recordMetadataFuture = producer.send(new ProducerRecord&lt;&gt;(topic,key, String.valueOf(i))); try &#123; RecordMetadata record = recordMetadataFuture.get(10, TimeUnit.MICROSECONDS); System.out.println(record.toString()); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125; long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; /** * 异步发送+回调函数(消息以异步的方式发送，通过回调函数返回消息发送成功/失败) */ public static void wayThree() &#123; String brokeList = "39.96.117.232:9092"; String topic = "testTopic"; String key = "testKey"; Producer&lt;String, String&gt; producer = initProducer(brokeList); long before = System.currentTimeMillis(); System.out.println("发送前--&gt;"+before); for(int i=1 ;i&lt;10000;i++)&#123; producer.send(new ProducerRecord&lt;&gt;(topic, key, String.valueOf(i)), new Callback() &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; if(e==null)&#123; System.out.println("## 发送消息成功-&gt;"); &#125;else &#123; System.out.println("## 发送消息失败-&gt;&#123;&#125;"+e.getMessage()); &#125; &#125; &#125;); &#125; long after = System.currentTimeMillis(); System.out.println("发送后--&gt;"+after); long temp = after-before; System.out.println("时间间隔--&gt;"+temp); &#125; /** * 初始化producer * @param brokeList * @return */ private static Producer&lt;String, String&gt; initProducer(String brokeList) &#123; Properties props = new Properties(); props.put("bootstrap.servers", brokeList); props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("retries", 0); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); return producer; &#125;&#125;]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka安装与入门]]></title>
    <url>%2F2019%2F05%2F31%2FKafka%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[介绍Kafka 是一种高吞吐量的分布式发布订阅消息系统，有如下特性： 通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 高吞吐量 ：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。 支持通过Kafka服务器和消费机集群来分区消息。 支持Hadoop并行数据加载。 Kafka通过官网发布了最新版本2.0.0 安装 基于Linux和macos操作系统 参考 http://kafka.apache.org/quickstart http://orchome.com/6 Step 1: 下载代码 下载2.2.0版本并解压缩 12$ tar -xzf kafka_2.12-2.2.0.tgz$ cd kafka_2.12-2.2.0 Step 2: 启动服务 运行kafka需要使用Zookeeper，所以你需要先启动Zookeeper，如果你没有Zookeeper，你可以使用kafka自带打包和配置好的Zookeeper。1$ bin/zookeeper-server-start.sh config/zookeeper.properties 现在启动kafka服务1$ bin/kafka-server-start.sh config/server.properties &amp; 入门 主要介绍发送Kafka消息，消费kafka消息等简单示例代码，以及使用过程中遇到的问题和解决方案 发送kafka消息示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.ohaotian.datatransmission.core.writer.kafka;import com.alibaba.fastjson.JSONObject;import lombok.extern.log4j.Log4j2;import org.apache.kafka.clients.producer.Callback;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.Producer;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;import java.util.Properties;/** * @Author: feifz * @Date: 2019-05-31 14:58 * @Version: 1.0 * @Description: kafka 发送消息示例 */@Log4j2public class KafkaProducerDemo &#123; public static void main(String[] args) &#123; String brokeList = "127.0.0.1:9092"; String topic = "testTopic"; String key = "testKey"; String message = "this is a test kafka message!"; Producer&lt;String, String&gt; producer = initProducer(brokeList); producer.send(new ProducerRecord&lt;&gt;(topic, key, JSONObject.toJSONString(message)), new Callback() &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; if (e == null) &#123; log.info("## 发送消息成功-&gt;&#123;&#125;", JSONObject.toJSONString(message)); &#125; else &#123; log.error("## 发送消息失败-&gt;&#123;&#125;", e.getMessage()); &#125; &#125; &#125;); producer.close(); &#125; /** * 初始化producer * @param brokeList * @return */ private static Producer&lt;String, String&gt; initProducer(String brokeList) &#123; Properties props = new Properties(); props.put("bootstrap.servers", brokeList); props.put("acks", "all"); props.put("retries", 0); props.put("batch.size", 16384); props.put("linger.ms", 1); props.put("buffer.memory", 33554432L); props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); return producer; &#125;&#125; 监控 参考：https://www.orchome.com/55 Kafka Manager简介为了简化开发者和服务工程师维护Kafka集群的工作，构建了一个叫做Kafka管理器的基于Web工具，叫做 Kafka Manager。这个管理工具可以很容易地发现分布在集群中的哪些topic分布不均匀，或者是分区在整个集群分布不均匀的的情况。它支持管理多个集群、选择副本、副本重新分配以及创建Topic。同时，这个管理工具也是一个非常好的可以快速浏览这个集群的工具。 该软件是用Scala语言编写的。目前(2015年02月03日)雅虎已经开源了Kafka Manager工具。这款Kafka集群管理工具主要支持以下几个功能： 管理几个不同的集群；很容易地检查集群的状态(topics, brokers, 副本的分布, 分区的分布)；选择副本；产生分区分配(Generate partition assignments)基于集群的当前状态；重新分配分区。 安装要求Kafka 0.8.. or 0.9.. or 0.10.. or 0.11..Java 8+sbt 0.13.x 配置系统至少需要配置zookeeper集群的地址，可以在kafka-manager安装包的conf目录下面的application.conf文件中进行配置。例如：1kafka-manager.zkhosts="my.zookeeper.host.com:2181" 你可以指定多个zookeeper地址，用逗号分隔：1kafka-manager.zkhosts="my.zookeeper.host.com:2181,other.zookeeper.host.com:2181" 另外, 如果你不想硬编码，可以使用环境变量ZK_HOSTS。1kafka-ZK_HOSTS="my.zookeeper.host.com:2181" 你可以启用/禁止以下的功能，通过修改application.config:1application.features=["KMClusterManagerFeature","KMTopicManagerFeature","KMPreferredReplicaElectionFeature","KMReassignPartitionsFeature"] KMClusterManagerFeature - 允许从Kafka Manager添加，更新，删除集群。KMTopicManagerFeature - 允许从Kafka集群中增加，更新，删除topicKMPreferredReplicaElectionFeature - 允许为Kafka集群运行首选副本KMReassignPartitionsFeature - 允许生成分区分配和重新分配分区考虑为启用了jmx的大群集设置这些参数： kafka-manager.broker-view-thread-pool-size=&lt; 3 * number_of_brokers&gt; kafka-manager.broker-view-max-queue-size=&lt; 3 * total # of partitions across all topics&gt; kafka-manager.broker-view-update-seconds=&lt; kafka-manager.broker-view-max-queue-size / (10 * number_of_brokers) &gt;下面是一个包含10个broker，100个topic的kafka集群示例，每个topic有10个分区，相当于1000个总分区，并启用JMX： kafka-manager.broker-view-thread-pool-size=30 kafka-manager.broker-view-max-queue-size=3000 kafka-manager.broker-view-update-seconds=30控制消费者偏offset缓存的线程池和队列： kafka-manager.offset-cache-thread-pool-size=&lt; default is # of processors&gt; kafka-manager.offset-cache-max-queue-size=&lt; default is 1000&gt; kafka-manager.kafka-admin-client-thread-pool-size=&lt; default is # of processors&gt; kafka-manager.kafka-admin-client-max-queue-size=&lt; default is 1000&gt;您应该在启用了消费者轮询的情况下为大量#消费者增加以上内容。虽然它主要影响基于ZK的消费者轮询。 Kafka管理的消费者offset现在由“__consumer_offsets”topic中的KafkaManagedOffsetCache消费。请注意，这尚未经过跟踪大量offset的测试。每个集群都有一个单独的线程消费这个topic，所以它可能无法跟上被推送到topic的大量offset。 部署下面的命令创建一个可部署应用的zip文件。1sbt clean dist 如果你不想拉源码，在编译，我已经编译好，放在百度云盘上了。 链接:https://pan.baidu.com/s/1AWQihB3CkF0g2Ao7lizTWw 密码:82eq 启动服务解压刚刚的zip文件,然后启动它:1$ bin/kafka-manager 默认情况下，端口为9000。可覆盖，例如：1$ bin/kafka-manager -Dconfig.file=/path/to/application.conf -Dhttp.port=8080 再如果java不在你的路径中，或你需要针对不同的版本，增加-java-home选项：1$ bin/kafka-manager -java-home /usr/local/oracle-java-8 用安全启动服务为SASL添加JAAS配置，添加配置文件位置：1$ bin/kafka-manager -Djava.security.auth.login.config=/path/to/my-jaas.conf 注意：确保运行kafka manager的用户有读取jaas配置文件的权限。 打包如果你想创建一个Debian或者RPM包，你可以使用下面命令打包：12sbt debian:packageBinsbt rpm:packageBin 常见问题1. 如何实现批量发送Kafka消息？生产者发送多个消息到同一个分区的时候，为了减少网络带来的系能开销，kafka会对消息进行批量发送。batch.size通过这个参数来设置批量提交的数据大小，默认是16k,当积压的消息达到这个值的时候就会统一发送（发往同一分区的消息）linger.ms这个设置是为发送设置一定是延迟来收集更多的消息，默认大小是0ms（就是有消息就立即发送）当这两个参数同时设置的时候，只要两个条件中满足一个就会发送。比如说batch.size设置16kb，linger.ms设置50ms，那么当消息积压达到16kb就会发送，如果没有到达16kb，那么在第一个消息到来之后的50ms之后消息将会发送。 2. Kafka如何保证消息的可靠性传输？这块比较常见的一个场景，就是Kafka某个broker宕机，然后重新选举partition 的leader。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader 挂了，然后选举某个follower成leader之后，不就少了一些数据？这就丢了一些数据啊。生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将follower切换为 leader 之后，就会发现说这个数据就丢了。所以此时一般是要求起码设置如下 4 个参数：给topic设置replication.factor参数：这个值必须大于1，要求每个 partition必须有至少2个副本。在Kafka服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧。在producer端设置 acks=all：这个是要求每条数据，必须是写入所有replica 之后，才能认为是写成功了。在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。我们生产环境就是按照上述要求配置的，这样配置之后，至少在Kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失。生产者会不会弄丢数据？如果按照上述的思路设置了acks=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch安装与入门]]></title>
    <url>%2F2019%2F05%2F31%2FElasticSearch%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[介绍 ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 安装ElasticSearch安装 进入官网下载页选择想要安装的版本下载：https://www.elastic.co/downloads/past-releases 解压缩至本地某地址 cd bin 执行命令:./elasticsearch 启动成功 ElasticSearch-head插件安装 （参考：https://blog.csdn.net/mingleizhen/article/details/76084874） 依赖环境：node和npm git clone https://github.com/mobz/elasticsearch-head.git npm install npm run start 修改ElasticSearch配置 在elasticsearch.yml添加如下配置 http.cors.enabled: true http.cors.allow-origin: “* 重启ES 页面访问：http://localhost:9100/ 启动完成 验证 访问：http://localhost:9100/]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>Elastic S e a r ch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发-线程池的使用]]></title>
    <url>%2F2019%2F05%2F29%2FJava%E5%B9%B6%E5%8F%91-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[说明 参考：https://www.cnblogs.com/dolphin0520/p/3932921.html 如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，因为频繁创建线程和销毁线程需要时间，这样频繁创建线程就会大大降低系统的效率。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？ 在Java中可以通过线程池来达到这样的效果。今天我们就来详细讲解一下Java的线程池，首先我们从最核心的ThreadPoolExecutor类中的方法讲起，然后再讲述它的实现原理，接着给出了它的使用示例，最后讨论了一下如何合理配置线程池的大小。 Java中的ThreadPoolExecutor类 java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// Public constructors and methods public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 下面解释下一下构造器中各个参数的含义： corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： 1234567TimeUnit.DAYS; //天TimeUnit.HOURS; //小时TimeUnit.MINUTES; //分钟TimeUnit.SECONDS; //秒TimeUnit.MILLISECONDS; //毫秒TimeUnit.MICROSECONDS; //微妙TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。 1234ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue;PriorityBlockingQueue threadFactory：线程工厂，主要用来创建线程； handler：表示当拒绝处理任务时的策略，有以下四种取值： 1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 具体参数的配置与线程池的关系将在下一节讲述。 从上面给出的ThreadPoolExecutor类的代码可以知道，ThreadPoolExecutor继承了AbstractExecutorService，我们来看一下AbstractExecutorService的实现： 123456789101112131415161718192021222324252627public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; &#125;; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; &#125;; public Future&lt;?&gt; submit(Runnable task) &#123;&#125;; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; &#125;; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; &#125;; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;;&#125; AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。 我们接着看ExecutorService接口的实现： 12345678910111213141516171819202122public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 而ExecutorService又是继承了Executor接口，我们看一下Executor接口的实现： 123public interface Executor &#123; void execute(Runnable command);&#125; 到这里，大家应该明白了ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor几个之间的关系了。 Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的； 然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等； 抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法； 然后ThreadPoolExecutor继承了类AbstractExecutorService。 在ThreadPoolExecutor类中有几个非常重要的方法： 1234execute()submit()shutdown()shutdownNow() execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果（Future相关内容将在下一篇讲述）。 shutdown()和shutdownNow()是用来关闭线程池的。 还有很多其他的方法： 比如：getQueue() 、getPoolSize() 、getActiveCount()、getCompletedTaskCount()等获取与线程池相关属性的方法，有兴趣的朋友可以自行查阅API。 深入剖析线程池实现原理在上一节我们从宏观上介绍了ThreadPoolExecutor，下面我们来深入解析一下线程池的具体实现原理，将从下面几个方面讲解： 1.线程池状态 2.任务的执行 3.线程池中的线程初始化 4.任务缓存队列及排队策略 5.任务拒绝策略 6.线程池的关闭 7.线程池容量的动态调整 1.线程池状态 在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态： 12345volatile int runState;static final int RUNNING = 0;static final int SHUTDOWN = 1;static final int STOP = 2;static final int TERMINATED = 3; runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性； 下面的几个static final变量表示runState可能的几个取值。 当创建线程池后，初始时，线程池处于RUNNING状态； 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 2.任务的执行 在了解将任务提交给线程池到任务执行完毕整个过程之前，我们先来看一下ThreadPoolExecutor类中其他的一些比较重要成员变量： 12345678910111213141516171819private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小 //、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集 private volatile long keepAliveTime; //线程存货时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数 private volatile int poolSize; //线程池中当前的线程数 private volatile RejectedExecutionHandler handler; //任务拒绝策略 private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程 private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; //用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子： 假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。 因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做； 当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待； 如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来； 然后就将任务也分配给这4个临时工人做； 如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。 当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。 也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。 不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。 largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 下面我们进入正题，看一下任务从提交到最终执行完毕经历了哪些过程。 在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可： 123456789101112public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123; if (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123; if (runState != RUNNING || poolSize == 0) ensureQueuedTaskHandled(command); &#125; else if (!addIfUnderMaximumPoolSize(command)) reject(command); // is shutdown or saturated &#125;&#125; 上面的代码可能看起来不是那么容易理解，下面我们一句一句解释： 首先，判断提交的任务command是否为null，若是null，则抛出空指针异常； 接着是这句，这句要好好理解一下： 1`if` `(poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command))` 由于是或条件运算符，所以先计算前半部分的值，如果线程池中当前线程数不小于核心池大小，那么就会直接进入下面的if语句块了。 如果线程池中当前线程数小于核心池大小，则接着执行后半部分，也就是执行 1`addIfUnderCorePoolSize(command)` 如果执行完addIfUnderCorePoolSize这个方法返回false，则继续执行下面的if语句块，否则整个方法就直接执行完毕了。 如果执行完addIfUnderCorePoolSize这个方法返回true，然后接着判断： 1`if` `(runState == RUNNING &amp;&amp; workQueue.offer(command))` 如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行： 1`addIfUnderMaximumPoolSize(command)` 如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。 回到前面： 1`if` `(runState == RUNNING &amp;&amp; workQueue.offer(command))` 这句的执行，如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续进行判断： 1`if` `(runState != RUNNING || poolSize == ``0``)` 这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施。如果是这样就执行： 1`ensureQueuedTaskHandled(command)` 进行应急处理，从名字可以看出是保证 添加到任务缓存队列中的任务得到处理。 我们接着看2个关键方法的实现：addIfUnderCorePoolSize和addIfUnderMaximumPoolSize： 1`private` `boolean` `addIfUnderCorePoolSize(Runnable firstTask) &#123;`` ``Thread t = ``null``;`` ``final` `ReentrantLock mainLock = ``this``.mainLock;`` ``mainLock.lock();`` ``try` `&#123;`` ``if` `(poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING)`` ``t = addThread(firstTask); ``//创建线程去执行firstTask任务 `` ``&#125; ``finally` `&#123;`` ``mainLock.unlock();`` ``&#125;`` ``if` `(t == ``null``)`` ``return` `false``;`` ``t.start();`` ``return` `true``;``&#125;` 这个是addIfUnderCorePoolSize方法的具体实现，从名字可以看出它的意图就是当低于核心池大小时执行的方法。下面看其具体实现，首先获取到锁，因为这地方涉及到线程池状态的变化，先通过if语句判断当前线程池中的线程数目是否小于核心池大小，有朋友也许会有疑问：前面在execute()方法中不是已经判断过了吗，只有线程池当前线程数目小于核心池大小才会执行addIfUnderCorePoolSize方法的，为何这地方还要继续判断？原因很简单，前面的判断过程中并没有加锁，因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了，所以需要在这个地方继续判断。然后接着判断线程池的状态是否为RUNNING，原因也很简单，因为有可能在其他线程中调用了shutdown或者shutdownNow方法。然后就是执行 1`t = addThread(firstTask);` 这个方法也非常关键，传进去的参数为提交的任务，返回值为Thread类型。然后接着在下面判断t是否为空，为空则表明创建线程失败（即poolSize&gt;=corePoolSize或者runState不等于RUNNING），否则调用t.start()方法启动线程。 我们来看一下addThread方法的实现： 1`private` `Thread addThread(Runnable firstTask) &#123;`` ``Worker w = ``new` `Worker(firstTask);`` ``Thread t = threadFactory.newThread(w); ``//创建一个线程，执行任务 `` ``if` `(t != ``null``) &#123;`` ``w.thread = t; ``//将创建的线程的引用赋值为w的成员变量 `` ``workers.add(w);`` ``int` `nt = ++poolSize; ``//当前线程数加1 `` ``if` `(nt &gt; largestPoolSize)`` ``largestPoolSize = nt;`` ``&#125;`` ``return` `t;``&#125;` 在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。 下面我们看一下Worker类的实现： 1`private` `final` `class` `Worker ``implements` `Runnable &#123;`` ``private` `final` `ReentrantLock runLock = ``new` `ReentrantLock();`` ``private` `Runnable firstTask;`` ``volatile` `long` `completedTasks;`` ``Thread thread;`` ``Worker(Runnable firstTask) &#123;`` ``this``.firstTask = firstTask;`` ``&#125;`` ``boolean` `isActive() &#123;`` ``return` `runLock.isLocked();`` ``&#125;`` ``void` `interruptIfIdle() &#123;`` ``final` `ReentrantLock runLock = ``this``.runLock;`` ``if` `(runLock.tryLock()) &#123;`` ``try` `&#123;`` ``if` `(thread != Thread.currentThread())`` ``thread.interrupt();`` ``&#125; ``finally` `&#123;`` ``runLock.unlock();`` ``&#125;`` ``&#125;`` ``&#125;`` ``void` `interruptNow() &#123;`` ``thread.interrupt();`` ``&#125;` ` ``private` `void` `runTask(Runnable task) &#123;`` ``final` `ReentrantLock runLock = ``this``.runLock;`` ``runLock.lock();`` ``try` `&#123;`` ``if` `(runState &lt; STOP &amp;&amp;`` ``Thread.interrupted() &amp;&amp;`` ``runState &gt;= STOP)`` ``boolean` `ran = ``false``;`` ``beforeExecute(thread, task); ``//beforeExecute方法是ThreadPoolExecutor类的一个方法，没有具体实现，用户可以根据`` ``//自己需要重载这个方法和后面的afterExecute方法来进行一些统计信息，比如某个任务的执行时间等 `` ``try` `&#123;`` ``task.run();`` ``ran = ``true``;`` ``afterExecute(task, ``null``);`` ``++completedTasks;`` ``&#125; ``catch` `(RuntimeException ex) &#123;`` ``if` `(!ran)`` ``afterExecute(task, ex);`` ``throw` `ex;`` ``&#125;`` ``&#125; ``finally` `&#123;`` ``runLock.unlock();`` ``&#125;`` ``&#125;` ` ``public` `void` `run() &#123;`` ``try` `&#123;`` ``Runnable task = firstTask;`` ``firstTask = ``null``;`` ``while` `(task != ``null` `|| (task = getTask()) != ``null``) &#123;`` ``runTask(task);`` ``task = ``null``;`` ``&#125;`` ``&#125; ``finally` `&#123;`` ``workerDone(``this``); ``//当任务队列中没有任务时，进行清理工作 `` ``&#125;`` ``&#125;``&#125;` 它实际上实现了Runnable接口，因此上面的Thread t = threadFactory.newThread(w);效果跟下面这句的效果基本一样： 1`Thread t = ``new` `Thread(w);` 相当于传进去了一个Runnable任务，在线程t中执行这个Runnable。 既然Worker实现了Runnable接口，那么自然最核心的方法便是run()方法了： 1`public` `void` `run() &#123;`` ``try` `&#123;`` ``Runnable task = firstTask;`` ``firstTask = ``null``;`` ``while` `(task != ``null` `|| (task = getTask()) != ``null``) &#123;`` ``runTask(task);`` ``task = ``null``;`` ``&#125;`` ``&#125; ``finally` `&#123;`` ``workerDone(``this``);`` ``&#125;``&#125;` 从run方法的实现可以看出，它首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，那么去哪里取呢？自然是从任务缓存队列里面去取，getTask是ThreadPoolExecutor类中的方法，并不是Worker类中的方法，下面是getTask方法的实现： 1`Runnable getTask() &#123;`` ``for` `(;;) &#123;`` ``try` `&#123;`` ``int` `state = runState;`` ``if` `(state &gt; SHUTDOWN)`` ``return` `null``;`` ``Runnable r;`` ``if` `(state == SHUTDOWN) ``// Help drain queue`` ``r = workQueue.poll();`` ``else` `if` `(poolSize &gt; corePoolSize || allowCoreThreadTimeOut) ``//如果线程数大于核心池大小或者允许为核心池线程设置空闲时间，`` ``//则通过poll取任务，若等待一定的时间取不到任务，则返回null`` ``r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS);`` ``else`` ``r = workQueue.take();`` ``if` `(r != ``null``)`` ``return` `r;`` ``if` `(workerCanExit()) &#123; ``//如果没取到任务，即r为null，则判断当前的worker是否可以退出`` ``if` `(runState &gt;= SHUTDOWN) ``// Wake up others`` ``interruptIdleWorkers(); ``//中断处于空闲状态的worker`` ``return` `null``;`` ``&#125;`` ``// Else retry`` ``&#125; ``catch` `(InterruptedException ie) &#123;`` ``// On interruption, re-check runState`` ``&#125;`` ``&#125;``&#125;` 在getTask中，先判断当前线程池状态，如果runState大于SHUTDOWN（即为STOP或者TERMINATED），则直接返回null。 如果runState为SHUTDOWN或者RUNNING，则从任务缓存队列取任务。 如果当前线程池的线程数大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，则调用poll(time,timeUnit)来取任务，这个方法会等待一定的时间，如果取不到任务就返回null。 然后判断取到的任务r是否为null，为null则通过调用workerCanExit()方法来判断当前worker是否可以退出，我们看一下workerCanExit()的实现： 1`private` `boolean` `workerCanExit() &#123;`` ``final` `ReentrantLock mainLock = ``this``.mainLock;`` ``mainLock.lock();`` ``boolean` `canExit;`` ``//如果runState大于等于STOP，或者任务缓存队列为空了`` ``//或者 允许为核心池线程设置空闲存活时间并且线程池中的线程数目大于1`` ``try` `&#123;`` ``canExit = runState &gt;= STOP ||`` ``workQueue.isEmpty() ||`` ``(allowCoreThreadTimeOut &amp;&amp;`` ``poolSize &gt; Math.max(``1``, corePoolSize));`` ``&#125; ``finally` `&#123;`` ``mainLock.unlock();`` ``&#125;`` ``return` `canExit;``&#125;` 也就是说如果线程池处于STOP状态、或者任务队列已为空或者允许为核心池线程设置空闲存活时间并且线程数大于1时，允许worker退出。如果允许worker退出，则调用interruptIdleWorkers()中断处于空闲状态的worker，我们看一下interruptIdleWorkers()的实现： 1`void` `interruptIdleWorkers() &#123;`` ``final` `ReentrantLock mainLock = ``this``.mainLock;`` ``mainLock.lock();`` ``try` `&#123;`` ``for` `(Worker w : workers) ``//实际上调用的是worker的interruptIfIdle()方法`` ``w.interruptIfIdle();`` ``&#125; ``finally` `&#123;`` ``mainLock.unlock();`` ``&#125;``&#125;` 从实现可以看出，它实际上调用的是worker的interruptIfIdle()方法，在worker的interruptIfIdle()方法中： 1`void` `interruptIfIdle() &#123;`` ``final` `ReentrantLock runLock = ``this``.runLock;`` ``if` `(runLock.tryLock()) &#123; ``//注意这里，是调用tryLock()来获取锁的，因为如果当前worker正在执行任务，锁已经被获取了，是无法获取到锁的`` ``//如果成功获取了锁，说明当前worker处于空闲状态`` ``try` `&#123;`` ``if` `(thread != Thread.currentThread()) `` ``thread.interrupt();`` ``&#125; ``finally` `&#123;`` ``runLock.unlock();`` ``&#125;`` ``&#125;``&#125;` 这里有一个非常巧妙的设计方式，假如我们来设计线程池，可能会有一个任务分派线程，当发现有线程空闲时，就从任务缓存队列中取一个任务交给空闲线程执行。但是在这里，并没有采用这样的方式，因为这样会要额外地对任务分派线程进行管理，无形地会增加难度和复杂度，这里直接让执行完任务的线程去任务缓存队列里面取任务来执行。 我们再看addIfUnderMaximumPoolSize方法的实现，这个方法的实现思想和addIfUnderCorePoolSize方法的实现思想非常相似，唯一的区别在于addIfUnderMaximumPoolSize方法是在线程池中的线程数达到了核心池大小并且往任务队列中添加任务失败的情况下执行的： 1`private` `boolean` `addIfUnderMaximumPoolSize(Runnable firstTask) &#123;`` ``Thread t = ``null``;`` ``final` `ReentrantLock mainLock = ``this``.mainLock;`` ``mainLock.lock();`` ``try` `&#123;`` ``if` `(poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING)`` ``t = addThread(firstTask);`` ``&#125; ``finally` `&#123;`` ``mainLock.unlock();`` ``&#125;`` ``if` `(t == ``null``)`` ``return` `false``;`` ``t.start();`` ``return` `true``;``&#125;` 看到没有，其实它和addIfUnderCorePoolSize方法的实现基本一模一样，只是if语句判断条件中的poolSize &lt; maximumPoolSize不同而已。 到这里，大部分朋友应该对任务提交给线程池之后到被执行的整个过程有了一个基本的了解，下面总结一下： 1）首先，要清楚corePoolSize和maximumPoolSize的含义； 2）其次，要知道Worker是用来起到什么作用的； 3）要知道任务提交给线程池之后的处理策略，这里总结一下主要有4点： 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 3.线程池中的线程初始化 默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 下面是这2个方法的实现： 1`public` `boolean` `prestartCoreThread() &#123;`` ``return` `addIfUnderCorePoolSize(``null``); ``//注意传进去的参数是null``&#125;` `public` `int` `prestartAllCoreThreads() &#123;`` ``int` `n = ``0``;`` ``while` `(addIfUnderCorePoolSize(``null``))``//注意传进去的参数是null`` ``++n;`` ``return` `n;``&#125;` 注意上面传进去的参数是null，根据第2小节的分析可知如果传进去的参数为null，则最后执行线程会阻塞在getTask方法中的 1`r = workQueue.take();` 即等待任务队列中有任务。 4.任务缓存队列及排队策略 在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。 workQueue的类型为BlockingQueue，通常可以取下面三种类型： 1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； 2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； 3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 5.任务拒绝策略 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： 1`ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。``ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。``ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）``ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务` 6.线程池的关闭 ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 7.线程池容量的动态调整 ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize：设置核心池大小 setMaximumPoolSize：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 使用示例前面我们讨论了关于线程池的实现原理，这一节我们来看一下它的具体使用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.ohaotian.feifz.style.study.thread;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author feifz * @version 1.0.0 * @Description 线程池示例 * @createTime 2019年05月28日 16:31:00 */public class ThreadDemoTest &#123; public static void main(String[] args) &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5)); for (int i = 0; i &lt; 15; i++) &#123; MyTask myTask = new MyTask(i); executor.execute(myTask); System.out.println("线程池中线程数目：" + executor.getPoolSize() + "，队列中等待执行的任务数目：" + executor.getQueue().size() + "，已执行玩别的任务数目：" + executor.getCompletedTaskCount()); &#125; executor.shutdown(); &#125;&#125;class MyTask implements Runnable &#123; private int taskNum; public MyTask(int num) &#123; this.taskNum = num; &#125; @Override public void run() &#123; System.out.println("正在执行task " + taskNum); try &#123; Thread.currentThread().sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("task " + taskNum + "执行完毕"); &#125;&#125; 从执行结果可以看出，当线程池中线程的数目大于5时，便将任务放入任务缓存队列里面，当任务缓存队列满了之后，便创建新的线程。如果上面程序中，将for循环中改成执行20个任务，就会抛出任务拒绝异常了。 不过在java doc中，并不提倡我们直接使用ThreadPoolExecutor，而是使用Executors类中提供的几个静态方法来创建线程池： 123Executors.newCachedThreadPool(); //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUEExecutors.newSingleThreadExecutor(); //创建容量为1的缓冲池Executors.newFixedThreadPool(int); //创建固定容量大小的缓冲池 下面是这三个静态方法的具体实现; 12345678910111213141516public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 从它们的具体实现来看，它们实际上也是调用了ThreadPoolExecutor，只不过参数都已配置好了。 newFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue； newSingleThreadExecutor将corePoolSize和maximumPoolSize都设置为1，也使用的LinkedBlockingQueue； newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 实际中，如果Executors提供的三个静态方法能满足要求，就尽量使用它提供的三个方法，因为自己去手动配置ThreadPoolExecutor的参数有点麻烦，要根据实际任务的类型和数量来进行配置。 另外，如果ThreadPoolExecutor达不到要求，可以自己继承ThreadPoolExecutor类进行重写。 如何合理配置线程池的大小本节来讨论一个比较重要的话题：如何合理配置线程池大小，仅供参考。 一般需要根据任务的类型来配置线程池大小： 如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1 如果是IO密集型任务，参考值可以设置为2*NCPU 当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。]]></content>
      <tags>
        <tag>Java并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo入门到进阶]]></title>
    <url>%2F2019%2F05%2F12%2FHexo%20%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 官方文档(这里主要记录本人在使用Hexo过程中遇到的问题和解决方案) 基本使用init1$ hexo init [folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new1$ hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 1$ hexo new "post title with whitespace" generate1$ hexo generate 生成静态文件。 选项 描述 -d, --deploy 文件生成后立即部署网站 -w, --watch 监视文件变动 该命令可以简写为1$ hexo g publish1$ hexo publish [layout] &lt;filename&gt; 发表草稿。 server1$ hexo server 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 选项 描述 -p, --port 重设端口 -s, --static 只使用静态文件 -l, --log 启动日记记录，使用覆盖记录格式 该命令可以简写为1234567$ hexo s`## deploy``` bash$ hexo deploy 部署网站。 参数 描述 -g, --generate 部署之前预先生成静态文件 该命令可以简写为：1$ hexo d render1$ hexo render &lt;file1&gt; [file2] ... 渲染文件。 参数 描述 -o, --output 设置输出路径 migrate1$ hexo migrate &lt;type&gt; 从其他博客系统 迁移内容。 clean1$ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 list1$ hexo list &lt;type&gt; 列出网站资料。 version1$ hexo version 插件Hexo-admin插件介绍hexo-admin 是一个Hexo博客引擎的管理用户界面插件。这个插件最初是作为本地编辑器设计的，在本地运行hexo使用hexo-admin编写文章，然后通过hexo g或hexo d（hexo g是本地渲染，hexo d是将渲染的静态页面发布到GitHub）将生成的静态页面发布到GitHub等静态服务器。如果你使用的是非静态托管服务器，比如自己买的主机搭建的hexo，那么一定要设置hexo-admin 的密码，否则谁都可以编辑你的文章。 插件安装首先进入hexo创建的博客项目的根目录下，执行1234567 npm install --save hexo-admin``` mac可能需要root权限，前面加个sudo 就可以了。如果报错缺少组件，则缺少什么安装什么，npm install 加缺少的组件。运行下列命令启动hexo-admin ：``` bash hexo server -d 打开 http://localhost:4000/admin/ 就可以访问到hexo-admin管理页面了。 密码保护打开setting，点击Setup authentification here输入用户名，密码，密钥，下面会自动生成配置文件，复制加在hexo根目录下的_config.yml中：1234admin: username: username password_hash: be121740bf988b2225a313fa1f107ca1 secret: secret 重启hexo，就可以看到登录页面了 发布文章进入后台之后点击Deploy，里面的Deploy按钮是用来执行发布脚本的，所以我们先在博客根目录下新建个目录admin_script，然后在目录中新建一个脚本hexo-g.sh，里面写下下面代码然后保存， hexo g &amp;&amp; hexo d 然后在_config.yml中的admin下添加 admin: username: username password_hash: be121740bf988b2225a313fa1f107ca1 secret: secret deployCommand: ./admin_script/hexo-g.sh 设置发布执行的脚本，点击Deploy就会执行这个命令并提交到GitHub上。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
